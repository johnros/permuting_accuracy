
@article{benjamini_controlling_1995,
  title = {Controlling the false discovery rate: a practical and powerful approach to multiple testing},
  volume = {57},
  shorttitle = {Controlling the false discovery rate},
  timestamp = {2013-04-28T13:10:53Z},
  journal = {JOURNAL-ROYAL STATISTICAL SOCIETY SERIES B},
  author = {Benjamini, Y. and Hochberg, Y.},
  year = {1995},
  keywords = {FDR,Seminal,Statistics},
  pages = {289--289},
  file = {Benjamini_Hochberg_1995_Controlling the false discovery rate.pdf:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/D5FV8QSI/Benjamini_Hochberg_1995_Controlling the false discovery rate.pdf:application/pdf;Controlling the False Discovery Rate\: A Practical and Powerful Approach to Multiple Testing:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/DDUCV4K7/2346101.html:text/html}
}

@book{vaart_asymptotic_1998,
  address = {Cambridge, UK ; New York, NY, USA},
  title = {Asymptotic {{Statistics}}},
  isbn = {978-0-521-49603-2},
  abstract = {Here is a practical and mathematically rigorous introduction to the field of asymptotic statistics. In addition to most of the standard topics of an asymptotics course--likelihood inference, M-estimation, the theory of asymptotic efficiency, U-statistics, and rank procedures--the book also presents recent research topics such as semiparametric models, the bootstrap, and empirical processes and their applications. The topics are organized from the central idea of approximation by limit experiments, one of the book's unifying themes that mainly entails the local approximation of the classical i.i.d. set up with smooth parameters by location experiments involving a single, normally distributed observation.},
  language = {English},
  timestamp = {2014-05-12T07:27:16Z},
  publisher = {{Cambridge University Press}},
  author = {{van der Vaart}, A. W.},
  month = oct,
  year = {1998}
}

@article{lehmann_parametric_2009,
  title = {Parametric versus nonparametrics: two alternative methodologies},
  volume = {21},
  issn = {1048-5252},
  shorttitle = {Parametric versus nonparametrics},
  doi = {10.1080/10485250902842727},
  abstract = {This article compares parametric and nonparametric approaches to statistical inference. It considers their advantages and disadvantages, and their areas of applicability. Although there is no clear comprehensive conclusion, the article finds that in simple problems in which Wilcoxon type tests and estimators apply, they may be recommended as the methods of choice.},
  timestamp = {2014-07-29T19:18:14Z},
  number = {4},
  urldate = {2012-06-11},
  journal = {Journal of Nonparametric Statistics},
  author = {Lehmann, Erich L.},
  year = {2009},
  pages = {397--405},
  file = {Lehmann_2009_Parametric versus nonparametrics.pdf:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/TUM867X9/Lehmann_2009_Parametric versus nonparametrics.pdf:application/pdf;Snapshot:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/VZ6JRE7S/10485250902842727.html:text/html}
}

@article{jimura_analyses_2012,
  series = {Multivoxel pattern analysis and cognitive theories},
  title = {Analyses of regional-average activation and multivoxel pattern information tell complementary stories},
  volume = {50},
  issn = {0028-3932},
  doi = {10.1016/j.neuropsychologia.2011.11.007},
  abstract = {Multivariate pattern analysis (MVPA) has recently received increasing attention in functional neuroimaging due to its ability to decode mental states from fMRI signals. However, questions remain regarding both the empirical and conceptual relationships between results from MVPA and standard univariate analyses. In the current study, whole-brain univariate and searchlight MVPAs of parametric manipulations of monetary gain and loss in a decision making task (Tom et al., 2007) were compared to identify the differences in the results across these methods and the implications for understanding the underlying mental processes. The MVPA and univariate results did identify some overlapping regions in whole brain analyses. However, an analysis of consistency revealed that in many regions the effect size estimates obtained from MVPA and univariate analysis were uncorrelated. Moreover, comparison of sensitivity showed a general trend towards greater sensitivity to task manipulations by MVPA compared to univariate analysis. These results demonstrate that MVPA methods may provide a different view of the functional organization of mental processing compared to univariate analysis, wherein MVPA is more sensitive to distributed coding of information whereas univariate analysis is more sensitive to global engagement in ongoing tasks. The results also highlight the need for better ways to integrate these methods.},
  timestamp = {2015-03-19T08:14:51Z},
  number = {4},
  urldate = {2015-03-19},
  journal = {Neuropsychologia},
  author = {Jimura, Koji and Poldrack, Russell A.},
  month = mar,
  year = {2012},
  keywords = {decision-making,fMRI,MVPA,Support vector regression,Univariate analysis},
  pages = {544--552},
  file = {Jimura_Poldrack_2012_Analyses of regional-average activation and multivoxel pattern information tell.pdf:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/XHK76TX4/Jimura_Poldrack_2012_Analyses of regional-average activation and multivoxel pattern information tell.pdf:application/pdf;ScienceDirect Snapshot:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/TUQNCDIP/S0028393211005070.html:text/html}
}

@article{kriegeskorte_information-based_2006,
  title = {Information-based functional brain mapping},
  volume = {103},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.0600244103},
  abstract = {The development of high-resolution neuroimaging and multielectrode electrophysiological recording provides neuroscientists with huge amounts of multivariate data. The complexity of the data creates a need for statistical summary, but the local averaging standardly applied to this end may obscure the effects of greatest neuroscientific interest. In neuroimaging, for example, brain mapping analysis has focused on the discovery of activation, i.e., of extended brain regions whose average activity changes across experimental conditions. Here we propose to ask a more general question of the data: Where in the brain does the activity pattern contain information about the experimental condition? To address this question, we propose scanning the imaged volume with a ``searchlight,'' whose contents are analyzed multivariately at each location in the brain.},
  language = {en},
  timestamp = {2015-03-31T16:52:56Z},
  number = {10},
  urldate = {2015-03-31},
  journal = {Proceedings of the National Academy of Sciences of the United States of America},
  author = {Kriegeskorte, Nikolaus and Goebel, Rainer and Bandettini, Peter},
  month = jul,
  year = {2006},
  keywords = {Functional Magnetic Resonance Imaging,Neuroimaging,Statistical analysis},
  pages = {3863--3868},
  file = {Kriegeskorte et al_2006_Information-based functional brain mapping.pdf:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/SGBTJT8B/Kriegeskorte et al_2006_Information-based functional brain mapping.pdf:application/pdf;Snapshot:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/P9ADDW3Q/3863.html:text/html},
  pmid = {16537458}
}

@book{anderson_introduction_2003,
  address = {Hoboken, NJ},
  edition = {3 edition},
  title = {An {{Introduction}} to {{Multivariate Statistical Analysis}}},
  isbn = {978-0-471-36091-9},
  abstract = {Perfected over three editions and more than forty years, this field- and classroom-tested reference: * Uses the method of maximum likelihood to a large extent to ensure reasonable, and in some cases optimal procedures. * Treats all the basic and important topics in multivariate statistics. * Adds two new chapters, along with a number of new sections. * Provides the most methodical, up-to-date information on MV statistics available.},
  language = {English},
  timestamp = {2015-05-04T06:37:32Z},
  publisher = {{Wiley-Interscience}},
  author = {Anderson, T. W.},
  month = jul,
  year = {2003}
}

@article{srivastava_two_2013,
  title = {A two sample test in high dimensional data},
  volume = {114},
  issn = {0047-259X},
  doi = {10.1016/j.jmva.2012.08.014},
  abstract = {In this paper we propose a test for testing the equality of the mean vectors of two groups with unequal covariance matrices based on N 1 and N 2 independently distributed p -dimensional observation vectors. It will be assumed that N 1 observation vectors from the first group are normally distributed with mean vector \ensuremath{\mu} 1 and covariance matrix \ensuremath{\Sigma} 1 . Similarly, the N 2 observation vectors from the second group are normally distributed with mean vector \ensuremath{\mu} 2 and covariance matrix \ensuremath{\Sigma} 2 . We propose a test for testing the hypothesis that \ensuremath{\mu} 1 = \ensuremath{\mu} 2 . This test is invariant under the group of p \texttimes{} p nonsingular diagonal matrices. The asymptotic distribution is obtained as ( N 1 , N 2 , p ) \ensuremath{\rightarrow} \ensuremath{\infty} and N 1 / ( N 1 + N 2 ) \ensuremath{\rightarrow} k \ensuremath{\in} ( 0 , 1 ) but N 1 / p and N 2 / p may go to zero or infinity. It is compared with a recently proposed non-invariant test. It is shown that the proposed test performs the best.},
  timestamp = {2015-05-31T14:04:32Z},
  urldate = {2015-05-31},
  journal = {Journal of Multivariate Analysis},
  author = {Srivastava, Muni S. and Katayama, Shota and Kano, Yutaka},
  month = feb,
  year = {2013},
  keywords = {Asymptotic theory,Behrensâ€“Fisher problem,High-dimensional data,Hypothesis testing},
  pages = {349--358},
  file = {Srivastava et al_2013_A two sample test in high dimensional data.pdf:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/HITJM4F3/Srivastava et al_2013_A two sample test in high dimensional data.pdf:application/pdf;ScienceDirect Snapshot:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/T8KIS5U9/S0047259X12002126.html:text/html}
}

@article{srivastava_test_2008,
  title = {A test for the mean vector with fewer observations than the dimension},
  volume = {99},
  issn = {0047-259X},
  doi = {10.1016/j.jmva.2006.11.002},
  abstract = {In this paper, we consider a test for the mean vector of independent and identically distributed multivariate normal random vectors where the dimension p is larger than or equal to the number of observations N. This test is invariant under scalar transformations of each component of the random vector. Theories and simulation results show that the proposed test is superior to other two tests available in the literature. Interest in such significance test for high-dimensional data is motivated by DNA microarrays. However, the methodology is valid for any application which involves high-dimensional data.},
  timestamp = {2015-06-01T11:56:51Z},
  number = {3},
  urldate = {2015-06-01},
  journal = {Journal of Multivariate Analysis},
  author = {Srivastava, Muni S. and Du, Meng},
  month = mar,
  year = {2008},
  keywords = {Asymptotic distribution,DNA microarray,Multivariate normal,Power comparison,Significance test},
  pages = {386--402},
  file = {Srivastava_Du_2008_A test for the mean vector with fewer observations than the dimension.pdf:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/7GXHRAJV/Srivastava_Du_2008_A test for the mean vector with fewer observations than the dimension.pdf:application/pdf;ScienceDirect Snapshot:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/ZM7JH2QS/S0047259X06001990.html:text/html}
}

@article{stelzer_statistical_2013,
  title = {Statistical inference and multiple testing correction in classification-based multi-voxel pattern analysis ({{MVPA}}): {{Random}} permutations and cluster size control},
  volume = {65},
  issn = {1053-8119},
  shorttitle = {Statistical inference and multiple testing correction in classification-based multi-voxel pattern analysis ({{MVPA}})},
  doi = {10.1016/j.neuroimage.2012.09.063},
  abstract = {An ever-increasing number of functional magnetic resonance imaging (fMRI) studies are now using information-based multi-voxel pattern analysis (MVPA) techniques to decode mental states. In doing so, they achieve a significantly greater sensitivity compared to when they use univariate frameworks. However, the new brain-decoding methods have also posed new challenges for analysis and statistical inference on the group level. We discuss why the usual procedure of performing t-tests on accuracy maps across subjects in order to produce a group statistic is inappropriate. We propose a solution to this problem for local MVPA approaches, which achieves higher sensitivity than other procedures. Our method uses random permutation tests on the single-subject level, and then combines the results on the group level with a bootstrap method. To preserve the spatial dependency induced by local MVPA methods, we generate a random permutation set and keep it fixed across all locations. This enables us to later apply a cluster size control for the multiple testing problem. More specifically, we explicitly compute the distribution of cluster sizes and use this to determine the p-values for each cluster. Using a volumetric searchlight decoding procedure, we demonstrate the validity and sensitivity of our approach using both simulated and real fMRI data sets. In comparison to the standard t-test procedure implemented in SPM8, our results showed a higher sensitivity. We discuss the theoretical applicability and the practical advantages of our approach, and outline its generalization to other local MVPA methods, such as surface decoding techniques.},
  timestamp = {2015-08-26T20:55:19Z},
  urldate = {2013-08-30},
  journal = {NeuroImage},
  author = {Stelzer, Johannes and Chen, Yi and Turner, Robert},
  month = jan,
  year = {2013},
  keywords = {Cluster size control,fMRI,Multiple testing,MVPA,Second level analysis,Statistics},
  pages = {69--82},
  file = {Stelzer et al_2013_Statistical inference and multiple testing correction in classification-based.pdf:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/C9BKWQSA/Stelzer et al_2013_Statistical inference and multiple testing correction in classification-based.pdf:application/pdf;ScienceDirect Snapshot:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/2NGS4Q2G/S1053811912009810.html:text/html;ScienceDirect Snapshot:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/BX4T8DK8/S1053811912009810.html:text/html}
}

@article{nadler_finite_2008,
  title = {Finite sample approximation results for principal component analysis: {{A}} matrix perturbation approach},
  volume = {36},
  issn = {0090-5364, 2168-8966},
  shorttitle = {Finite sample approximation results for principal component analysis},
  doi = {10.1214/08-AOS618},
  abstract = {Principal component analysis (PCA) is a standard tool for dimensional reduction of a set of n observations (samples), each with p variables. In this paper, using a matrix perturbation approach, we study the nonasymptotic relation between the eigenvalues and eigenvectors of PCA computed on a finite sample of size n, and those of the limiting population PCA as n\ensuremath{\rightarrow{}\infty}. As in machine learning, we present a finite sample theorem which holds with high probability for the closeness between the leading eigenvalue and eigenvector of sample PCA and population PCA under a spiked covariance model. In addition, we also consider the relation between finite sample PCA and the asymptotic results in the joint limit p, n\ensuremath{\rightarrow{}\infty}, with p/n=c. We present a matrix perturbation view of the ``phase transition phenomenon,'' and a simple linear-algebra based derivation of the eigenvalue and eigenvector overlap in this asymptotic limit. Moreover, our analysis also applies for finite p, n where we show that although there is no sharp phase transition as in the infinite case, either as a function of noise level or as a function of sample size n, the eigenvector of sample PCA may exhibit a sharp ``loss of tracking,'' suddenly losing its relation to the (true) eigenvector of the population PCA matrix. This occurs due to a crossover between the eigenvalue due to the signal and the largest eigenvalue due to noise, whose eigenvector points in a random direction.},
  language = {EN},
  timestamp = {2016-01-12T20:00:57Z},
  number = {6},
  urldate = {2016-01-12},
  journal = {The Annals of Statistics},
  author = {Nadler, Boaz},
  month = dec,
  year = {2008},
  keywords = {matrix perturbation,phase transition,principal component analysis,random matrix theory,spiked covariance model},
  pages = {2791--2817},
  file = {Nadler_2008_Finite sample approximation results for principal component analysis.pdf:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/K8SXK8TZ/Nadler_2008_Finite sample approximation results for principal component analysis.pdf:application/pdf;Snapshot:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/ZV3UZPQ7/1231165185.html:text/html},
  mrnumber = {MR2485013},
  zmnumber = {05503376}
}

@article{srivastava_testing_2013,
  title = {On testing the equality of mean vectors in high dimension},
  volume = {17},
  issn = {2228-4699},
  doi = {10.12697/ACUTM.2013.17.03},
  abstract = {In this article, we review various tests that have been proposed in the literature for testing the equality of several mean vectors. In particular, it includes testing the equality of two mean vectors, the so-called two-sample problem as well as that of testing the equality of several mean vectors, the so-called multivariate analysis of variance or MANOVA problem. The total sample size, however, may be less than the dimension of the mean vectors, and so usual tests cannot be used. Powers of these tests are compared using simulation.},
  language = {en},
  timestamp = {2016-02-01T12:13:48Z},
  number = {1},
  urldate = {2015-06-01},
  journal = {Acta et Commentationes Universitatis Tartuensis de Mathematica},
  author = {Srivastava, Muni S.},
  month = jun,
  year = {2013},
  keywords = {Equality of two mean vectors,high dimensional,inequality of two covariance matrices,Multivariate analysis of variance,sample smaller than dimension},
  pages = {31--56},
  file = {Srivastava_2013_On testing the equality of mean vectors in high dimension.pdf:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/CES3WQ63/Srivastava_2013_On testing the equality of mean vectors in high dimension.pdf:application/pdf;Snapshot:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/52BRBUCE/ACUTM.2013.17.html:text/html}
}

@article{blair_study_1994,
  title = {A {{Study}} of {{Multivariate Permutation Tests Which May Replace Hotelling}}'s {{T2 Test}} in {{Prescribed Circumstances}}},
  volume = {29},
  issn = {0027-3171},
  doi = {10.1207/s15327906mbr2902_2},
  abstract = {Multivariate permutation tests are described and studied which may be profitably substituted for Hotelling's one-sample P test in situations commonly arising in behavioral science research. These tests (a) may be computed even when the number of variables exceeds the number of subjects, (b) are distribution-free, (c) may be tailored for sensitivity to specific treatment alternatives, and (d) provide one-sided as well as two-sided tests of hypotheses. Power comparisons were made between the permutation tests and Hotelling's T(2) test under a variety of treatment effect model, correlation structure and number of variables combinations. Results show that the permutation tests have significant power advantages over the T(2) in a variety of circumstances, but may have considerably less power in others.},
  language = {eng},
  timestamp = {2016-02-06T10:27:37Z},
  number = {2},
  journal = {Multivariate Behavioral Research},
  author = {Blair, R. C. and Higgins, J. J. and Karniski, W. and Kromrey, J. D.},
  month = apr,
  year = {1994},
  pages = {141--163},
  file = {Blair et al_1994_A Study of Multivariate Permutation Tests Which May Replace Hotelling's T2 Test.pdf:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/J6QZ69DU/Blair et al_1994_A Study of Multivariate Permutation Tests Which May Replace Hotelling's T2 Test.pdf:application/pdf;Snapshot:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/XGSVCHPR/s15327906mbr2902_2.html:text/html},
  pmid = {26745025}
}

@article{ramdas_classification_2016,
  title = {Classification {{Accuracy}} as a {{Proxy}} for {{Two Sample Testing}}},
  abstract = {When data analysts train a classifier and check if its accuracy is significantly different from random guessing, they are implicitly and indirectly performing a hypothesis test (two sample testing) and it is of importance to ask whether this indirect method for testing is statistically optimal or not. Given that hypothesis tests attempt to maximize statistical power subject to a bound on the allowable false positive rate, while prediction attempts to minimize statistical risk on future predictions on unseen data, we wish to study whether a predictive approach for an ultimate aim of testing is prudent. We formalize this problem by considering the two-sample mean-testing setting where one must determine if the means of two Gaussians (with known and equal covariance) are the same or not, but the analyst indirectly does so by checking whether the accuracy achieved by Fisher's LDA classifier is significantly different from chance or not. Unexpectedly, we find that the asymptotic power of LDA's sample-splitting classification accuracy is actually minimax rate-optimal in terms of problem-dependent parameters. Since prediction is commonly thought to be harder than testing, it might come as a surprise to some that solving a harder problem does not create a information-theoretic bottleneck for the easier one. On the flip side, even though the power is rate-optimal, our derivation suggests that it may be worse by a small constant factor; hence practitioners must be wary of using (admittedly flexible) prediction methods on disguised testing problems.},
  timestamp = {2016-02-15T08:29:52Z},
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1602.02210},
  primaryClass = {cs, math, stat},
  urldate = {2016-02-09},
  journal = {arXiv:1602.02210 [cs, math, stat]},
  author = {Ramdas, Aaditya and Singh, Aarti and Wasserman, Larry},
  month = feb,
  year = {2016},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Learning,Mathematics - Statistics Theory,Statistics - Machine Learning},
  annote = {Comment: 15 pages, 2 figures},
  file = {Ramdas et al_2016_Classification Accuracy as a Proxy for Two Sample Testing.pdf:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/MD57BQS4/Ramdas et al_2016_Classification Accuracy as a Proxy for Two Sample Testing.pdf:application/pdf;arXiv.org Snapshot:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/ANXGBH2J/1602.html:text/html}
}

@article{srivastava_multivariate_2007,
  title = {Multivariate {{Theory}} for {{Analyzing High Dimensional Data}}},
  volume = {37},
  doi = {10.14490/jjss.37.53},
  abstract = {In this article, we develop a multivariate theory for analyzing multivariate datasets that have fewer observations than dimensions. More specifically, we consider the problem of testing the hypothesis that the mean vector \ensuremath{\mu} of a p-dimensional random vector x is a zero vector where N, the number of independent observations on x, is less than the dimension p. It is assumed that x is normally distributed with mean vector \ensuremath{\mu} and unknown nonsingular covariance matrix \ensuremath{\sum}. We propose the test statistic F+ = n-2 (p - n + 1) N \textasciimacron{}x\ensuremath{'}S+\textasciimacron{}x, where n = N - 1 \ensuremath{<} p, \textasciimacron{}x and S are the sample mean vector and the sample covariance matrix respectively, and S+ is the Moore-Penrose inverse of S. It is shown that a suitably normalized version of the F+ statistic is asymptotically normally distributed under the hypothesis. The asymptotic non-null distribution in one sample case is given. The case when the covariance matrix \ensuremath{\sum} is singular of rank r but the sample size N is larger than r is also considered. The corresponding results for the case of two-samples and k samples, known as MANOVA, are given.},
  timestamp = {2016-02-17T04:59:33Z},
  number = {1},
  journal = {Journal of the Japan Statistical Society},
  author = {Srivastava, M. S.},
  year = {2007},
  keywords = {Distribution of test statistics,DNA microarray data,Fewer observations than dimension,Multivariate analysis of variance,Singular Wishart},
  pages = {53--86},
  file = {Srivastava_2007_Multivariate Theory for Analyzing High Dimensional Data.pdf:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/RN68APQJ/Srivastava_2007_Multivariate Theory for Analyzing High Dimensional Data.pdf:application/pdf}
}

@article{mumford_deconvolving_2012,
  title = {Deconvolving {{BOLD}} activation in event-related designs for multivoxel pattern classification analyses},
  volume = {59},
  issn = {1053-8119},
  doi = {10.1016/j.neuroimage.2011.08.076},
  abstract = {Use of multivoxel pattern analysis (MVPA) to predict the cognitive state of a subject during task performance has become a popular focus of fMRI studies. The input to these analyses consists of activation patterns corresponding to different tasks or stimulus types. These activation patterns are fairly straightforward to calculate for blocked trials or slow event-related designs, but for rapid event-related designs the evoked BOLD signal for adjacent trials will overlap in time, complicating the identification of signal unique to specific trials. Rapid event-related designs are often preferred because they allow for more stimuli to be presented and subjects tend to be more focused on the task, and thus it would be beneficial to be able to use these types of designs in MVPA analyses. The present work compares 8 different models for estimating trial-by-trial activation patterns for a range of rapid event-related designs varying by interstimulus interval and signal-to-noise ratio. The most effective approach obtains each trial's estimate through a general linear model including a regressor for that trial as well as another regressor for all other trials. Through the analysis of both simulated and real data we have found that this model shows some improvement over the standard approaches for obtaining activation patterns. The resulting trial-by-trial estimates are more representative of the true activation magnitudes, leading to a boost in classification accuracy in fast event-related designs with higher signal-to-noise. This provides the potential for fMRI studies that allow simultaneous optimization of both univariate and MVPA approaches.},
  timestamp = {2016-03-10T15:50:34Z},
  number = {3},
  urldate = {2016-03-10},
  journal = {NeuroImage},
  author = {Mumford, Jeanette A. and Turner, Benjamin O. and Ashby, F. Gregory and Poldrack, Russell A.},
  month = feb,
  year = {2012},
  keywords = {Beta series estimation,classification analysis,Functional Magnetic Resonance Imaging,MVPA,Rapid event-related design},
  pages = {2636--2643},
  annote = {The subject of this paper:
~
- Seen as a prediction problem, the challenge is to correctly associate a stimulous, with its corresponding spatial pattern.
~
~
\_\_Questions of interest:\_\_
~
- How is accurate classification problem related to the signal detection problem?
~
- Is the optimal filter for detection, the same as the optimal filter for classification? (probably not).
~
- Will using the wrong HRF cause dependence between estimates?
~
~- Why are the one-against-all regressors not correlated? Because one-against all esentially measures the marginal~correlation, and not the
conditional correlation measured by the multivariate regression.~~
~
~
\_\_ Possible problem with this paper:\_\_
~
- How is the chance level set?
~
- Support vector regression (SVR) does not regularize. It merely uses differet target functions (quantile regression).
~
- The success of one-against-all depends the particular design, because the betas abosorb all other correlated effects. The true winner thus thus be the mass-univariate regression.
},
  file = {Mumford et al_2012_Deconvolving BOLD activation in event-related designs for multivoxel pattern.pdf:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/6F6XSHTW/Mumford et al_2012_Deconvolving BOLD activation in event-related designs for multivoxel pattern.pdf:application/pdf;ScienceDirect Snapshot:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/2W45BQQJ/S1053811911010081.html:text/html}
}

@article{mumford_impact_2014,
  title = {The impact of study design on pattern estimation for single-trial multivariate pattern analysis},
  volume = {103},
  issn = {1053-8119},
  doi = {10.1016/j.neuroimage.2014.09.026},
  abstract = {A prerequisite for a pattern analysis using functional magnetic resonance imaging (fMRI) data is estimating the patterns from time series data, which then are input into the pattern analysis. Here we focus on how the combination of study design (order and spacing of trials) with pattern estimator impacts the Type I error rate of the subsequent pattern analysis. When Type I errors are inflated, the results are no longer valid, so this work serves as a guide for designing and analyzing MVPA studies with controlled false positive rates. The MVPA strategies examined are pattern classification and similarity, utilizing single trial activation patterns from the same functional run. Primarily focusing on the Least Squares Single and Least Square All pattern estimators, we show that collinearities in the models, along with temporal autocorrelation, can cause false positive correlations between activation pattern estimates that adversely impact the false positive rates of pattern similarity and classification analyses. It may seem intuitive that increasing the interstimulus interval (ISI) would alleviate this issue, but remaining weak correlations between activation patterns persist and have a strong influence in pattern similarity analyses. Pattern similarity analyses using only activation patterns estimated from the same functional run of data are susceptible to inflated false positives unless trials are randomly ordered, with a different randomization for each subject. In other cases, where there is any structure to trial order, valid pattern similarity analysis results can only be obtained if similarity computations are restricted to pairs of activation patterns from independent runs. Likewise, for pattern classification, false positives are minimized when the testing and training sets in cross validation do not contain patterns estimated from the same run.},
  timestamp = {2016-03-20T21:16:42Z},
  urldate = {2016-03-20},
  journal = {NeuroImage},
  author = {Mumford, Jeanette A. and Davis, Tyler and Poldrack, Russell A.},
  month = dec,
  year = {2014},
  keywords = {False positive rate,fMRI,MVPA,pattern classification,Pattern similarity},
  pages = {130--138},
  annote = {A study of the (parametric) random-effect covariance of beta estimates, for the purposes of experimental design.
This means that design is optimized for parametric RFX inference. Not for non-parametric FFX as in Stelzer, or others.},
  file = {Mumford et al_2014_The impact of study design on pattern estimation for single-trial multivariate.pdf:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/ZXGTRKTZ/Mumford et al_2014_The impact of study design on pattern estimation for single-trial multivariate.pdf:application/pdf;ScienceDirect Snapshot:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/IXZRT8C4/S105381191400768X.html:text/html}
}

@book{fujikoshi_multivariate_2011,
  title = {Multivariate {{Statistics}}: {{High-Dimensional}} and {{Large-Sample Approximations}}},
  isbn = {978-0-470-53986-6},
  shorttitle = {Multivariate {{Statistics}}},
  abstract = {A comprehensive examination of high-dimensional analysis of multivariate methods and their real-world applications Multivariate Statistics: High-Dimensional and Large-Sample Approximations is the first book of its kind to explore how classical multivariate methods can be revised and used in place of conventional statistical tools. Written by prominent researchers in the field, the book focuses on high-dimensional and large-scale approximations and details the many basic multivariate methods used to achieve high levels of accuracy. The authors begin with a fundamental presentation of the basic tools and exact distributional results of multivariate statistics, and, in addition, the derivations of most distributional results are provided. Statistical methods for high-dimensional data, such as curve data, spectra, images, and DNA microarrays, are discussed. Bootstrap approximations from a methodological point of view, theoretical accuracies in MANOVA tests, and model selection criteria are also presented. Subsequent chapters feature additional topical coverage including:  High-dimensional approximations of various statistics High-dimensional statistical methods Approximations with computable error bound Selection of variables based on model selection approach Statistics with error bounds and their appearance in discriminant analysis, growth curve models, generalized linear models, profile analysis, and multiple comparison  Each chapter provides real-world applications and thorough analyses of the real data. In addition, approximation formulas found throughout the book are a useful tool for both practical and theoretical statisticians, and basic results on exact distributions in multivariate analysis are included in a comprehensive, yet accessible, format. Multivariate Statistics is an excellent book for courses on probability theory in statistics at the graduate level. It is also an essential reference for both practical and theoretical statisticians who are interested in multivariate analysis and who would benefit from learning the applications of analytical probabilistic methods in statistics.},
  language = {en},
  timestamp = {2016-05-01T07:19:13Z},
  publisher = {{John Wiley \& Sons}},
  author = {Fujikoshi, Yasunori and Ulyanov, Vladimir V. and Shimizu, Ryoichi},
  month = aug,
  year = {2011},
  keywords = {Mathematics / Probability \& Statistics / General,Mathematics / Probability \& Statistics / Stochastic Processes}
}

@article{pernet_human_2015,
  title = {The human voice areas: {{Spatial}} organization and inter-individual variability in temporal and extra-temporal cortices},
  volume = {119},
  issn = {1053-8119},
  shorttitle = {The human voice areas},
  doi = {10.1016/j.neuroimage.2015.06.050},
  abstract = {fMRI studies increasingly examine functions and properties of non-primary areas of human auditory cortex. However there is currently no standardized localization procedure to reliably identify specific areas across individuals such as the standard `localizers' available in the visual domain. Here we present an fMRI `voice localizer' scan allowing rapid and reliable localization of the voice-sensitive `temporal voice areas' (TVA) of human auditory cortex. We describe results obtained using this standardized localizer scan in a large cohort of normal adult subjects. Most participants (94\%) showed bilateral patches of significantly greater response to vocal than non-vocal sounds along the superior temporal sulcus/gyrus (STS/STG). Individual activation patterns, although reproducible, showed high inter-individual variability in precise anatomical location. Cluster analysis of individual peaks from the large cohort highlighted three bilateral clusters of voice-sensitivity, or ``voice patches'' along posterior (TVAp), mid (TVAm) and anterior (TVAa) STS/STG, respectively. A series of extra-temporal areas including bilateral inferior prefrontal cortex and amygdalae showed small, but reliable voice-sensitivity as part of a large-scale cerebral voice network. Stimuli for the voice localizer scan and probabilistic maps in MNI space are available for download.},
  timestamp = {2016-05-03T07:43:38Z},
  urldate = {2015-08-13},
  journal = {NeuroImage},
  author = {Pernet, Cyril R. and McAleer, Phil and Latinus, Marianne and Gorgolewski, Krzysztof J. and Charest, Ian and Bestelmeyer, Patricia E. G. and Watson, Rebecca H. and Fleming, David and Crabbe, Frances and Valdes-Sosa, Mitchell and Belin, Pascal},
  month = oct,
  year = {2015},
  keywords = {Amygdala,Auditory Cortex,Functional Magnetic Resonance Imaging,Inferior prefrontal cortex,Superior temporal gyrus,Superior temporal sulcus,Voice},
  pages = {164--174},
  file = {Pernet et al_2015_The human voice areas.pdf:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/K5P9IBIC/Pernet et al_2015_The human voice areas.pdf:application/pdf;Pernet et al_2015_The human voice areas.pdf:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/TMDRCDKR/Pernet et al_2015_The human voice areas.pdf:application/pdf;ScienceDirect Snapshot:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/CPWNAN2U/S1053811915005558.html:text/html;ScienceDirect Snapshot:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/DUHB2G28/S1053811915005558.html:text/html}
}

@book{hastie_elements_2003,
  title = {The {{Elements}} of {{Statistical Learning}}},
  isbn = {0-387-95284-5},
  abstract = {During the past decade there has been an explosion in computation and information technology. With it has come vast amounts of data in a variety of fields such as medicine, biology, finance, and marketing. The challenge of understanding these data has led to the development of new tools in the field of statistics, and spawned new areas such as data mining, machine learning, and bioinformatics.

Many of these tools have common underpinnings but are often expressed with different terminology. This book describes the important ideas in these areas in a common conceptual framework. While the approach is statistical, the emphasis is on concepts rather than mathematics. Many examples are given, with a liberal use of color graphics. It should be a valuable resource for statisticians and anyone interested in data mining in science or industry.

The book's coverage is broad, from supervised learning (prediction) to unsupervised learning. The many topics include neural networks, support vector machines, classification trees and boosting--the first comprehensive treatment of this topic in any book.

Trevor Hastie, Robert Tibshirani, and Jerome Friedman are professors of statistics at Stanford University. They are prominent researchers in this area: Hastie and Tibshirani developed generalized additive models and wrote a popular book of that title. Hastie wrote much of the statistical modeling software in S-PLUS and invented principal curves and surfaces. Tibshirani proposed the Lasso and is co-author of the very successful An Introduction to the Bootstrap. Friedman is the co-inventor of many data-mining tools including CART, MARS, and projection pursuit.

FROM THE REVIEWS:

TECHNOMETRICS "[This] is a vast and complex book. Generally, it concentrates on explaining why and how the methods work, rather than how to use them. Examples and especially the visualizations are principle features...As a source for the methods of statistical learning...it will probably be a long time before there is a competitor to this book."},
  timestamp = {2016-05-17T05:02:03Z},
  urldate = {2014-12-11},
  publisher = {{Springer}},
  author = {Hastie, T and Tibshirani, R and Friedman, JH},
  month = jul,
  year = {2003},
  keywords = {machine-learning,machine-learning,statistic,statistic}
}

@article{ojala_permutation_2010,
  title = {Permutation {{Tests}} for {{Studying Classifier Performance}}},
  volume = {11},
  issn = {ISSN 1533-7928},
  timestamp = {2016-07-04T17:58:55Z},
  number = {Jun},
  urldate = {2016-07-04},
  journal = {Journal of Machine Learning Research},
  author = {Ojala, Markus and Garriga, Gemma C.},
  year = {2010},
  pages = {1833--1863},
  file = {Ojala_Garriga_2010_Permutation Tests for Studying Classifier Performance.pdf:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/3JAFGW2X/Ojala_Garriga_2010_Permutation Tests for Studying Classifier Performance.pdf:application/pdf;Snapshot:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/Z5T8DEE6/ojala10a.html:text/html}
}

@article{schafer_shrinkage_2005,
  title = {A shrinkage approach to large-scale covariance matrix estimation and implications for functional genomics},
  volume = {4},
  timestamp = {2016-07-04T21:03:44Z},
  number = {1},
  urldate = {2016-07-04},
  journal = {Statistical applications in genetics and molecular biology},
  author = {Sch{\"a}fer, Juliane and Strimmer, Korbinian and {others}},
  year = {2005},
  pages = {32},
  file = {SchÃ¤fer et al_2005_A shrinkage approach to large-scale covariance matrix estimation and.pdf:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/AXE5W4FW/SchÃ¤fer et al_2005_A shrinkage approach to large-scale covariance matrix estimation and.pdf:application/pdf}
}

@unpublished{varoquaux_assessing_2016,
  title = {Assessing and tuning brain decoders: cross-validation, caveats, and guidelines},
  shorttitle = {Assessing and tuning brain decoders},
  abstract = {Decoding, ie prediction from brain images or signals, calls for empirical evaluation of its predictive power. Such evaluation is achieved via cross-validation, a method also used to tune decoders' hyper-parameters. This paper is a review on cross-validation procedures for decoding in neuroimaging. It includes a didactic overview of the relevant theoretical considerations. Practical aspects are highlighted with an extensive empirical study of the common decoders in within-and across-subject predictions, on multiple datasets \textendash{}anatomical and functional MRI and MEG\textendash{} and simulations. Theory and experiments outline that the popular " leave-one-out " strategy leads to unstable and biased estimates, and a repeated random splits method should be preferred. Experiments outline the large error bars of cross-validation in neuroimaging settings: typical confidence intervals of 10\%. Nested cross-validation can tune decoders' parameters while avoiding circularity bias. However we find that it can be more favorable to use sane defaults, in particular for non-sparse decoders.},
  timestamp = {2016-07-04T21:08:54Z},
  urldate = {2016-07-04},
  author = {Varoquaux, Ga{\"e}l and Raamana, Pradeep Reddy and Engemann, Denis and Hoyos-Idrobo, Andr{\'e}s and Schwartz, Yannick and Thirion, Bertrand},
  month = jun,
  year = {2016},
  note = {working paper or preprint},
  keywords = {Bagging,cross-validation,Decoding,fMRI,Model selection,MVPA,sparse},
  file = {Varoquaux et al_2016_Assessing and tuning brain decoders.pdf:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/GM2G3W2W/Varoquaux et al_2016_Assessing and tuning brain decoders.pdf:application/pdf;HAL Snapshot:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/XSPCKFJR/hal-01332785.html:text/html}
}

@inproceedings{golland_permutation_2003,
  title = {Permutation tests for classification: towards statistical significance in image-based studies},
  volume = {3},
  shorttitle = {Permutation tests for classification},
  timestamp = {2016-07-05T10:33:44Z},
  urldate = {2016-07-05},
  booktitle = {{{IPMI}}},
  publisher = {{Springer}},
  author = {Golland, Polina and Fischl, Bruce},
  year = {2003},
  pages = {330--341},
  file = {Golland_Fischl_2003_Permutation tests for classification.pdf:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/KIFCRANG/Golland_Fischl_2003_Permutation tests for classification.pdf:application/pdf;Snapshot:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/5PZMV3JR/b11820.html:text/html}
}

@article{radmacher_paradigm_2002,
  title = {A {{Paradigm}} for {{Class Prediction Using Gene Expression Profiles}}},
  volume = {9},
  issn = {1066-5277},
  doi = {10.1089/106652702760138592},
  abstract = {We propose a general framework for prediction of predefined tumor classes using gene expression profiles from microarray experiments. The framework consists of 1) evaluating the appropriateness of class          prediction for the given data set, 2) selecting the prediction method, 3) performing cross-validated class prediction, and 4) assessing the significance of prediction results by permutation testing. We          describe an application of the prediction paradigm to gene expression profiles from human breast cancers, with specimens classified as positive or negative for BRCA1 mutations and also for BRCA2          mutations. In both cases, the accuracy of class prediction was statistically significant when compared to the accuracy of prediction expected by chance. The framework proposed here for the application of          class prediction is designed to reduce the occurrence of spurious findings, a legitimate concern for high-dimensional microarray data. The prediction paradigm will serve as a good framework for comparing          different prediction methods and may accelerate the development of molecular classifiers that are clinically useful.},
  timestamp = {2016-07-21T08:48:15Z},
  number = {3},
  urldate = {2016-07-21},
  journal = {Journal of Computational Biology},
  author = {Radmacher, Michael D. and McShane, Lisa M. and Simon, Richard},
  month = jun,
  year = {2002},
  pages = {505--511},
  file = {Radmacher et al_2002_A Paradigm for Class Prediction Using Gene Expression Profiles.pdf:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/RE86PPTC/Radmacher et al_2002_A Paradigm for Class Prediction Using Gene Expression Profiles.pdf:application/pdf;Snapshot:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/MP5I69DB/106652702760138592.html:text/html}
}

@article{nadeau_inference_????,
  title = {Inference for the {{Generalization Error}}},
  volume = {52},
  issn = {0885-6125, 1573-0565},
  doi = {10.1023/A:1024068626366},
  abstract = {In order to compare learning algorithms, experimental results reported in the machine learning literature often use statistical tests of significance to support the claim that a new learning algorithm generalizes better. Such tests should take into account the variability due to the choice of training set and not only that due to the test examples, as is often the case. This could lead to gross underestimation of the variance of the cross-validation estimator, and to the wrong conclusion that the new algorithm is significantly better when it is not. We perform a theoretical investigation of the variance of a variant of the cross-validation estimator of the generalization error that takes into account the variability due to the randomness of the training set as well as test examples. Our analysis shows that all the variance estimators that are based only on the results of the cross-validation experiment must be biased. This analysis allows us to propose new estimators of this variance. We show, via simulations, that tests of hypothesis about the generalization error using those new variance estimators have better properties than tests involving variance estimators currently in use and listed in Dietterich (1998). In particular, the new tests have correct size and good power. That is, the new tests do not reject the null hypothesis too often when the hypothesis is true, but they tend to frequently reject the null hypothesis when the latter is false.},
  language = {en},
  timestamp = {2016-07-21T08:56:33Z},
  number = {3},
  urldate = {2016-07-21},
  journal = {Machine Learning},
  author = {Nadeau, Claude and Bengio, Yoshua},
  pages = {239--281},
  file = {Nadeau_Bengio_Inference for the Generalization Error.pdf:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/TDV3832D/Nadeau_Bengio_Inference for the Generalization Error.pdf:application/pdf;Snapshot:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/7SKKZM3H/A1024068626366.html:text/html}
}

@article{jiang_calculating_2008,
  title = {Calculating confidence intervals for prediction error in microarray classification using resampling},
  volume = {7},
  timestamp = {2016-07-21T09:02:59Z},
  number = {1},
  urldate = {2016-07-21},
  journal = {Statistical Applications in Genetics and Molecular Biology},
  author = {Jiang, Wenyu and Varma, Sudhir and Simon, Richard},
  year = {2008},
  file = {Jiang et al_2008_Calculating confidence intervals for prediction error in microarray.pdf:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/XSSU5F5W/Jiang et al_2008_Calculating confidence intervals for prediction error in microarray.pdf:application/pdf;Snapshot:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/4H86NDA9/sagmb.2008.7.1.1322.html:text/html}
}

@article{gilron_quantifying_2016,
  title = {Quantifying spatial pattern similarity in multivariate analysis using functional anisotropy},
  abstract = {Multivoxel pattern analysis (MVPA) has gained enormous popularity in the neuroimaging community over the past few years. At the group level, most MVPA studies adopt an "information based" approach in which the sign of the effect of individual subjects is discarded and a non-directional summary statistic is carried over to the second level. This is in contrast to a directional "activation based" approach which is typical in univariate group level analysis, in which both signal magnitude and sign are taken into account. The transition from examining effects in one voxel at a time vs. several voxels (univariate vs. multivariate) has thus tacitly entailed a transition from directional to non-directional signal definition at the group level. While a directional MVPA approach implies that individuals share multivariate spatial patterns of activity, in a non-directional approach each individual may have a distinct spatial pattern of activity. Here we show using an experimental dataset that indeed directional and non-directional MVPA approaches uncover distinct brain regions with some overlap. Moreover, we developed a descriptive measure to quantify the degree to which subjects share spatial patterns of activity. Our approach is based on adapting the Fractional Anisotropy (FA) measure, originally developed for examining diffusion MRI signals, in a novel way to quantify the degree to which subjects share a spatial pattern of activity. We term this measure "Functional Anisotropy" (FuA). Applying FuA to an auditory task, we found higher values in primary auditory regions compared to secondary and control regions. This highlights the potential of the FuA measure in second-level MVPA analysis to detect differences in the consistency of spatial patterns across subjects and their relationship to functional domains in the brain.},
  timestamp = {2016-07-26T04:06:39Z},
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1605.03482},
  primaryClass = {q-bio},
  urldate = {2016-07-26},
  journal = {arXiv:1605.03482 [q-bio]},
  author = {Gilron, Roee and Rosenblatt, Jonathan and Koyejo, Oluwasanmi and Poldrack, Russell A. and Mukamel, Roy},
  month = may,
  year = {2016},
  keywords = {Quantitative Biology - Neurons and Cognition,Quantitative Biology - Quantitative Methods},
  file = {Gilron et al_2016_Quantifying spatial pattern similarity in multivariate analysis using.pdf:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/3AE7RZEB/Gilron et al_2016_Quantifying spatial pattern similarity in multivariate analysis using.pdf:application/pdf;arXiv.org Snapshot:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/F5VJ3TWX/1605.html:text/html}
}

@article{hemerik_exact_2014,
  title = {Exact testing with random permutations},
  abstract = {Permutation tests and other methods based on the permutation principle are highly popular, for instance in omics data analysis. Often random permutations are used, to limit the computation time. However, the existing theory on permutation tests usually assumes that all permutations are enumerated; little theory exists on testing with random permutations. It is known that naively using random permutations instead of the full permutation group, leads to anti-conservativeness. Also it has been claimed that adding the original observation to the random permutations solves this problem. A proof however is lacking. In this paper existing claims on validity of tests with random permutations are proven. Further, novel exact tests are presented.},
  timestamp = {2016-07-27T08:31:25Z},
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1411.7565},
  primaryClass = {math, stat},
  urldate = {2016-07-27},
  journal = {arXiv:1411.7565 [math, stat]},
  author = {Hemerik, Jesse and Goeman, Jelle},
  month = nov,
  year = {2014},
  keywords = {62G09,Mathematics - Statistics Theory},
  annote = {Comment: This version of the article is more focused and reader-friendly},
  file = {Hemerik_Goeman_2014_Exact testing with random permutations.pdf:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/DK287DKI/Hemerik_Goeman_2014_Exact testing with random permutations.pdf:application/pdf;arXiv.org Snapshot:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/GKQ23FZS/1411.html:text/html}
}

@article{pereira_machine_2009,
  series = {Mathematics in Brain Imaging},
  title = {Machine learning classifiers and {{fMRI}}: {{A}} tutorial overview},
  volume = {45},
  issn = {1053-8119},
  shorttitle = {Machine learning classifiers and {{fMRI}}},
  doi = {10.1016/j.neuroimage.2008.11.007},
  abstract = {Interpreting brain image experiments requires analysis of complex, multivariate data. In recent years, one analysis approach that has grown in popularity is the use of machine learning algorithms to train classifiers to decode stimuli, mental states, behaviours and other variables of interest from fMRI data and thereby show the data contain information about them. In this tutorial overview we review some of the key choices faced in using this approach as well as how to derive statistically significant results, illustrating each point from a case study. Furthermore, we show how, in addition to answering the question of `is there information about a variable of interest' (pattern discrimination), classifiers can be used to tackle other classes of question, namely `where is the information' (pattern localization) and `how is that information encoded' (pattern characterization).},
  timestamp = {2016-07-28T05:45:34Z},
  number = {1, Supplement 1},
  urldate = {2016-07-28},
  journal = {NeuroImage},
  author = {Pereira, Francisco and Mitchell, Tom and Botvinick, Matthew},
  month = mar,
  year = {2009},
  pages = {S199--S209},
  file = {Pereira et al_2009_Machine learning classifiers and fMRI.pdf:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/BNQ4Z2SM/Pereira et al_2009_Machine learning classifiers and fMRI.pdf:application/pdf;ScienceDirect Snapshot:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/SIQXCRCC/S1053811908012263.html:text/html}
}

@incollection{olivetti_induction_2012,
  series = {Lecture Notes in Computer Science},
  title = {Induction in {{Neuroscience}} with {{Classification}}: {{Issues}} and {{Solutions}}},
  copyright = {\textcopyright{}2012 Springer-Verlag Berlin Heidelberg},
  isbn = {978-3-642-34712-2 978-3-642-34713-9},
  shorttitle = {Induction in {{Neuroscience}} with {{Classification}}},
  abstract = {Machine learning and pattern recognition techniques are increasingly adopted in neuroimaging-based neuroscience research. In many applications a classifier is trained on brain data in order to predict a variable of interest. Two leading examples are brain decoding and clinical diagnosis. Brain decoding consists of predicting stimuli or mental states from concurrent functional brain data. In clinical diagnosis it is the presence or absence of a given medical condition that is predicted from brain data. Observing accurate classification is considered to support the hypothesis of variable-related information within brain data. In this work we briefly review the literature on statistical tests for this kind of hypothesis testing problem. We claim that the current approaches to this hypothesis testing problem are suboptimal, do not cover all useful settings, and that they could lead to wrong conclusions. We present a more accurate statistical test and provide examples of its superiority.},
  language = {en},
  timestamp = {2016-07-28T05:46:50Z},
  number = {7263},
  urldate = {2016-07-28},
  booktitle = {Machine {{Learning}} and {{Interpretation}} in {{Neuroimaging}}},
  publisher = {{Springer Berlin Heidelberg}},
  author = {Olivetti, Emanuele and Greiner, Susanne and Avesani, Paolo},
  editor = {Langs, Georg and Rish, Irina and Grosse-Wentrup, Moritz and Murphy, Brian},
  year = {2012},
  keywords = {Computer Applications,Computer Imaging; Vision; Pattern Recognition and Graphics,Data Mining and Knowledge Discovery,Image Processing and Computer Vision,pattern recognition,Probability and Statistics in Computer Science},
  pages = {42--50},
  file = {Olivetti et al_2012_Induction in Neuroscience with Classification.pdf:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/DNCZRCNJ/Olivetti et al_2012_Induction in Neuroscience with Classification.pdf:application/pdf;Snapshot:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/TF8AQ2N9/978-3-642-34713-9_6.html:text/html},
  doi = {10.1007/978-3-642-34713-9_6}
}

@article{simon_pitfalls_2003,
  title = {Pitfalls in the {{Use}} of {{DNA Microarray Data}} for {{Diagnostic}} and {{Prognostic Classification}}},
  volume = {95},
  issn = {0027-8874, 1460-2105},
  doi = {10.1093/jnci/95.1.14},
  language = {en},
  timestamp = {2016-07-28T06:02:48Z},
  number = {1},
  urldate = {2016-07-28},
  journal = {Journal of the National Cancer Institute},
  author = {Simon, Richard and Radmacher, Michael D. and Dobbin, Kevin and McShane, Lisa M.},
  month = jan,
  year = {2003},
  pages = {14--18},
  file = {Simon et al_2003_Pitfalls in the Use of DNA Microarray Data for Diagnostic and Prognostic.pdf:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/S2N3HXB2/Simon et al_2003_Pitfalls in the Use of DNA Microarray Data for Diagnostic and Prognostic.pdf:application/pdf;Snapshot:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/TPKZHDS4/14.html:text/html},
  pmid = {12509396}
}

@article{fu_estimating_2005,
  title = {Estimating misclassification error with small samples via bootstrap cross-validation},
  volume = {21},
  issn = {1367-4803, 1460-2059},
  doi = {10.1093/bioinformatics/bti294},
  abstract = {Motivation: Estimation of misclassification error has received increasing attention in clinical diagnosis and bioinformatics studies, especially in small sample studies with microarray data. Current error estimation methods are not satisfactory because they either have large variability (such as leave-one-out cross-validation) or large bias (such as resubstitution and leave-one-out bootstrap). While small sample size remains one of the key features of costly clinical investigations or of microarray studies that have limited resources in funding, time and tissue materials, accurate and easy-to-implement error estimation methods for small samples are desirable and will be beneficial.
Results: A bootstrap cross-validation method is studied. It achieves accurate error estimation through a simple procedure with bootstrap resampling and only costs computer CPU time. Simulation studies and applications to microarray data demonstrate that it performs consistently better than its competitors. This method possesses several attractive properties: (1) it is implemented through a simple procedure; (2) it performs well for small samples with sample size, as small as 16; (3) it is not restricted to any particular classification rules and thus applies to many parametric or non-parametric methods.
Contact: wfu@stat.tamu.edu},
  language = {en},
  timestamp = {2016-07-28T10:16:50Z},
  number = {9},
  urldate = {2016-07-28},
  journal = {Bioinformatics},
  author = {Fu, Wenjiang J. and Carroll, Raymond J. and Wang, Suojin},
  month = jan,
  year = {2005},
  pages = {1979--1986},
  file = {Fu et al_2005_Estimating misclassification error with small samples via bootstrap.pdf:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/32HCSCVH/Fu et al_2005_Estimating misclassification error with small samples via bootstrap.pdf:application/pdf;Snapshot:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/AUPFQ73E/1979.html:text/html},
  pmid = {15691862}
}

@article{bzdok_neuroimaging_2016,
  title = {Neuroimaging {{Research}}: {{From Null-Hypothesis Falsification}} to {{Out}}-of-sample {{Generalization}}},
  shorttitle = {Neuroimaging {{Research}}},
  abstract = {Brain imaging technology has boosted the quantification of neurobiological phenomena underlying human mental operations and their disturbances. Since its inception, drawing inference on neurophysiological effects hinged on classical statistical methods, especially, the general linear model. The tens of thousands variables per brain scan were routinely tackled by independent statistical tests on each voxel. This circumvented the curse of dimensionality in exchange for neurobiologically imperfect observation units, a challenging multiple comparisons problem, and limited scaling to currently growing data repositories. Yet, the always-bigger information granularity of neuroimaging data repositories has lunched a rapidly increasing adoption of statistical learning algorithms. These scale naturally to high-dimensional data, extract models from data rather than prespecifying them, and are empirically evaluated for extrapolation to unseen data. The present paper portrays commonalities and differences between long-standing classical inference and upcoming generalization inference relevant for conducting neuroimaging research.},
  timestamp = {2016-07-31T15:42:35Z},
  urldate = {2016-07-31},
  journal = {Educational and Psychological Measurement},
  author = {Bzdok, Danilo and Varoquaux, Ga{\"e}l and Thirion, Bertrand},
  month = aug,
  year = {2016},
  file = {Bzdok et al_2016_Neuroimaging Research.pdf:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/SVUEEE65/Bzdok et al_2016_Neuroimaging Research.pdf:application/pdf;HAL Snapshot:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/SCITXXGU/hal-01338313.html:text/html}
}

@article{wu_genome-wide_2009,
  title = {Genome-wide association analysis by lasso penalized logistic regression},
  volume = {25},
  issn = {1367-4803, 1460-2059},
  doi = {10.1093/bioinformatics/btp041},
  abstract = {Motivation: In ordinary regression, imposition of a lasso penalty makes continuous model selection straightforward. Lasso penalized regression is particularly advantageous when the number of predictors far exceeds the number of observations.
Method: The present article evaluates the performance of lasso penalized logistic regression in case\textendash{}control disease gene mapping with a large number of SNPs (single nucleotide polymorphisms) predictors. The strength of the lasso penalty can be tuned to select a predetermined number of the most relevant SNPs and other predictors. For a given value of the tuning constant, the penalized likelihood is quickly maximized by cyclic coordinate ascent. Once the most potent marginal predictors are identified, their two-way and higher order interactions can also be examined by lasso penalized logistic regression.
Results: This strategy is tested on both simulated and real data. Our findings on coeliac disease replicate the previous SNP results and shed light on possible interactions among the SNPs.
Availability: The software discussed is available in Mendel 9.0 at the UCLA Human Genetics web site.
Contact: klange@ucla.edu
Supplementary information: Supplementary data are available at Bioinformatics online.},
  language = {en},
  timestamp = {2016-07-31T16:33:16Z},
  number = {6},
  urldate = {2016-07-31},
  journal = {Bioinformatics},
  author = {Wu, Tong Tong and Chen, Yi Fang and Hastie, Trevor and Sobel, Eric and Lange, Kenneth},
  month = mar,
  year = {2009},
  pages = {714--721},
  file = {Wu et al_2009_Genome-wide association analysis by lasso penalized logistic regression.pdf:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/Q3ZNM95I/Wu et al_2009_Genome-wide association analysis by lasso penalized logistic regression.pdf:application/pdf;Snapshot:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/J3FEGJ9X/714.html:text/html},
  pmid = {19176549}
}

@article{wager_fmri-based_2013,
  title = {An {{fMRI-Based Neurologic Signature}} of {{Physical Pain}}},
  volume = {368},
  issn = {0028-4793},
  doi = {10.1056/NEJMoa1204471},
  abstract = {The experience of pain is poorly understood. The authors describe a neurologic signature that discriminates between the sensations of painful heat and nonpainful heat, is specific to physical pain, and is responsive to the analgesic agent remifentanil.},
  timestamp = {2016-07-31T16:47:07Z},
  number = {15},
  urldate = {2016-07-31},
  journal = {New England Journal of Medicine},
  author = {Wager, Tor D. and Atlas, Lauren Y. and Lindquist, Martin A. and Roy, Mathieu and Woo, Choong-Wan and Kross, Ethan},
  month = apr,
  year = {2013},
  pages = {1388--1397},
  file = {Wager et al_2013_An fMRI-Based Neurologic Signature of Physical Pain.pdf:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/B4KJHPBJ/Wager et al_2013_An fMRI-Based Neurologic Signature of Physical Pain.pdf:application/pdf;Snapshot:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/8UDMPBKV/NEJMoa1204471.html:text/html},
  pmid = {23574118}
}

@article{gabrieli_prediction_2015,
  title = {Prediction as a {{Humanitarian}} and {{Pragmatic Contribution}} from {{Human Cognitive Neuroscience}}},
  volume = {85},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2014.10.047},
  abstract = {Neuroimaging has greatly enhanced the cognitive neuroscience understanding of the human brain and its variation across individuals (neurodiversity) in both health and disease. Such progress has not yet, however, propelled changes in educational or medical practices that improve people's lives. We review neuroimaging findings in which initial brain measures (neuromarkers) are correlated with or predict future education, learning, and performance in children and adults; criminality; health-related behaviors; and responses to pharmacological or behavioral treatments. Neuromarkers often provide better predictions (neuroprognosis), alone or in combination with other measures, than traditional behavioral measures. With further advances in study designs and analyses, neuromarkers may offer opportunities to personalize educational and clinical practices that lead to better outcomes for people.},
  language = {English},
  timestamp = {2016-07-31T16:47:10Z},
  number = {1},
  urldate = {2016-07-31},
  journal = {Neuron},
  author = {Gabrieli, John D. E. and Ghosh, Satrajit S. and Whitfield-Gabrieli, Susan},
  month = jan,
  year = {2015},
  pages = {11--26},
  file = {Gabrieli et al_2015_Prediction as a Humanitarian and Pragmatic Contribution from Human Cognitive.pdf:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/2DQVWC6B/Gabrieli et al_2015_Prediction as a Humanitarian and Pragmatic Contribution from Human Cognitive.pdf:application/pdf;Snapshot:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/BVW7PT6C/S0896-6273(14)00967-2.html:text/html},
  pmid = {25569345, 25569345}
}

@article{olivetti_statistical_2014,
  title = {Statistical independence for the evaluation of classifier-based diagnosis},
  volume = {2},
  issn = {2198-4018, 2198-4026},
  doi = {10.1007/s40708-014-0007-6},
  abstract = {Machine learning techniques are increasingly adopted in computer-aided diagnosis. Evaluation methods for classification results that are based on the study of one or more metrics can be unable to distinguish between cases in which the classifier is discriminating the classes from cases in which it is not. In the binary setting, such circumstances can be encountered when data are unbalanced with respect to the diagnostic groups. Having more healthy controls than pathological subjects, datasets meant for diagnosis frequently show a certain degree of unbalancedness. In this work, we propose to recast the evaluation of classification results as a test of statistical independence between the predicted and the actual diagnostic groups. We address the problem within the Bayesian hypothesis testing framework. Different from the standard metrics, the proposed method is able to handle unbalanced data and takes into account the size of the available data. We show experimental evidence of the efficacy of the approach both on simulated data and on real data about the diagnosis of the Attention Deficit Hyperactivity Disorder (ADHD).},
  language = {en},
  timestamp = {2016-07-31T18:57:51Z},
  number = {1},
  urldate = {2016-07-31},
  journal = {Brain Informatics},
  author = {Olivetti, Emanuele and Greiner, Susanne and Avesani, Paolo},
  month = dec,
  year = {2014},
  pages = {13--19},
  file = {Olivetti et al_2014_Statistical independence for the evaluation of classifier-based diagnosis.pdf:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/WKF38NPF/Olivetti et al_2014_Statistical independence for the evaluation of classifier-based diagnosis.pdf:application/pdf;Snapshot:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/79SXWP64/s40708-014-0007-6.html:text/html}
}

@incollection{vayatis_auc_2009,
  title = {{{AUC}} optimization and the two-sample problem},
  timestamp = {2016-07-31T19:08:49Z},
  urldate = {2016-07-31},
  booktitle = {Advances in {{Neural Information Processing Systems}} 22},
  publisher = {{Curran Associates, Inc.}},
  author = {Vayatis, Nicolas and Depecker, Marine and Cl{\'e}men{\c c}con, St{\'e}phan J.},
  editor = {Bengio, Y. and Schuurmans, D. and Lafferty, J. D. and Williams, C. K. I. and Culotta, A.},
  year = {2009},
  pages = {360--368},
  file = {Vayatis et al_2009_AUC optimization and the two-sample problem.pdf:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/72UPSU78/Vayatis et al_2009_AUC optimization and the two-sample problem.pdf:application/pdf;NIPS Snapshort:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/FS3AZ8MR/3838-auc-optimization-and-the-two-sample-problem.html:text/html}
}

@article{gretton_kernel_2012,
  title = {A {{Kernel Two-Sample Test}}},
  volume = {13},
  issn = {ISSN 1533-7928},
  timestamp = {2016-07-31T19:09:11Z},
  number = {Mar},
  urldate = {2016-07-31},
  journal = {Journal of Machine Learning Research},
  author = {Gretton, Arthur and Borgwardt, Karsten M. and Rasch, Malte J. and Sch{\"o}lkopf, Bernhard and Smola, Alexander},
  year = {2012},
  pages = {723--773},
  file = {Gretton et al_2012_A Kernel Two-Sample Test.pdf:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/GSTU3PBK/Gretton et al_2012_A Kernel Two-Sample Test.pdf:application/pdf;Snapshot:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/FE27P35Z/gretton12a.html:text/html}
}

@article{casella_assessing_2009,
  title = {Assessing {{Robustness}} of {{Intrinsic Tests}} of {{Independence}} in {{Two-Way Contingency Tables}}},
  volume = {104},
  issn = {0162-1459},
  doi = {10.1198/jasa.2009.tm08106},
  timestamp = {2016-07-31T19:11:46Z},
  number = {487},
  urldate = {2016-07-31},
  journal = {Journal of the American Statistical Association},
  author = {Casella, George and Moreno, El{\'\i}as},
  month = sep,
  year = {2009},
  pages = {1261--1271},
  file = {Casella_Moreno_2009_Assessing Robustness of Intrinsic Tests of Independence in Two-Way Contingency.pdf:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/B4AFMUVH/Casella_Moreno_2009_Assessing Robustness of Intrinsic Tests of Independence in Two-Way Contingency.pdf:application/pdf;Snapshot:/home/johnros/.zotero/zotero/vs27un40.default/zotero/storage/6UJABK53/jasa.2009.html:text/html}
}


