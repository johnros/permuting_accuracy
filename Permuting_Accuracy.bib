
@article{mumford_deconvolving_2012,
  title = {Deconvolving {{BOLD}} activation in event-related designs for multivoxel pattern classification analyses},
  volume = {59},
  issn = {1053-8119},
  doi = {10.1016/j.neuroimage.2011.08.076},
  abstract = {Use of multivoxel pattern analysis (MVPA) to predict the cognitive state of a subject during task performance has become a popular focus of fMRI studies. The input to these analyses consists of activation patterns corresponding to different tasks or stimulus types. These activation patterns are fairly straightforward to calculate for blocked trials or slow event-related designs, but for rapid event-related designs the evoked BOLD signal for adjacent trials will overlap in time, complicating the identification of signal unique to specific trials. Rapid event-related designs are often preferred because they allow for more stimuli to be presented and subjects tend to be more focused on the task, and thus it would be beneficial to be able to use these types of designs in MVPA analyses. The present work compares 8 different models for estimating trial-by-trial activation patterns for a range of rapid event-related designs varying by interstimulus interval and signal-to-noise ratio. The most effective approach obtains each trial's estimate through a general linear model including a regressor for that trial as well as another regressor for all other trials. Through the analysis of both simulated and real data we have found that this model shows some improvement over the standard approaches for obtaining activation patterns. The resulting trial-by-trial estimates are more representative of the true activation magnitudes, leading to a boost in classification accuracy in fast event-related designs with higher signal-to-noise. This provides the potential for fMRI studies that allow simultaneous optimization of both univariate and MVPA approaches.},
  timestamp = {2016-03-10T15:50:34Z},
  number = {3},
  urldate = {2016-03-10},
  journal = {NeuroImage},
  author = {Mumford, Jeanette A. and Turner, Benjamin O. and Ashby, F. Gregory and Poldrack, Russell A.},
  month = feb,
  year = {2012},
  keywords = {Beta series estimation,classification analysis,Functional Magnetic Resonance Imaging,MVPA,Rapid event-related design},
  pages = {2636--2643},
  file = {Mumford et al_2012_Deconvolving BOLD activation in event-related designs for multivoxel pattern.pdf:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/6F6XSHTW/Mumford et al_2012_Deconvolving BOLD activation in event-related designs for multivoxel pattern.pdf:application/pdf;ScienceDirect Snapshot:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/2W45BQQJ/S1053811911010081.html:text/html}
}

@article{blair_study_1994,
  title = {A {{Study}} of {{Multivariate Permutation Tests Which May Replace Hotelling}}'s {{T2 Test}} in {{Prescribed Circumstances}}},
  volume = {29},
  issn = {0027-3171},
  doi = {10.1207/s15327906mbr2902_2},
  abstract = {Multivariate permutation tests are described and studied which may be profitably substituted for Hotelling's one-sample P test in situations commonly arising in behavioral science research. These tests (a) may be computed even when the number of variables exceeds the number of subjects, (b) are distribution-free, (c) may be tailored for sensitivity to specific treatment alternatives, and (d) provide one-sided as well as two-sided tests of hypotheses. Power comparisons were made between the permutation tests and Hotelling's T(2) test under a variety of treatment effect model, correlation structure and number of variables combinations. Results show that the permutation tests have significant power advantages over the T(2) in a variety of circumstances, but may have considerably less power in others.},
  language = {eng},
  timestamp = {2016-02-06T10:27:37Z},
  number = {2},
  journal = {Multivariate Behavioral Research},
  author = {Blair, R. C. and Higgins, J. J. and Karniski, W. and Kromrey, J. D.},
  month = apr,
  year = {1994},
  pages = {141--163},
  file = {Blair et al_1994_A Study of Multivariate Permutation Tests Which May Replace Hotelling's T2 Test.pdf:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/J6QZ69DU/Blair et al_1994_A Study of Multivariate Permutation Tests Which May Replace Hotelling's T2 Test.pdf:application/pdf;Snapshot:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/XGSVCHPR/s15327906mbr2902_2.html:text/html},
  pmid = {26745025}
}

@article{benjamini_controlling_1995,
  title = {Controlling the false discovery rate: a practical and powerful approach to multiple testing},
  volume = {57},
  shorttitle = {Controlling the false discovery rate},
  timestamp = {2013-04-28T13:10:53Z},
  journal = {JOURNAL-ROYAL STATISTICAL SOCIETY SERIES B},
  author = {Benjamini, Y. and Hochberg, Y.},
  year = {1995},
  keywords = {FDR,Seminal,Statistics},
  pages = {289--289},
  file = {Benjamini_Hochberg_1995_Controlling the false discovery rate.pdf:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/D5FV8QSI/Benjamini_Hochberg_1995_Controlling the false discovery rate.pdf:application/pdf;Controlling the False Discovery Rate\: A Practical and Powerful Approach to Multiple Testing:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/DDUCV4K7/2346101.html:text/html}
}

@book{hastie_elements_2003-1,
  title = {The {{Elements}} of {{Statistical Learning}}},
  isbn = {0-387-95284-5},
  abstract = {During the past decade there has been an explosion in computation and information technology. With it has come vast amounts of data in a variety of fields such as medicine, biology, finance, and marketing. The challenge of understanding these data has led to the development of new tools in the field of statistics, and spawned new areas such as data mining, machine learning, and bioinformatics.

Many of these tools have common underpinnings but are often expressed with different terminology. This book describes the important ideas in these areas in a common conceptual framework. While the approach is statistical, the emphasis is on concepts rather than mathematics. Many examples are given, with a liberal use of color graphics. It should be a valuable resource for statisticians and anyone interested in data mining in science or industry.

The book's coverage is broad, from supervised learning (prediction) to unsupervised learning. The many topics include neural networks, support vector machines, classification trees and boosting--the first comprehensive treatment of this topic in any book.

Trevor Hastie, Robert Tibshirani, and Jerome Friedman are professors of statistics at Stanford University. They are prominent researchers in this area: Hastie and Tibshirani developed generalized additive models and wrote a popular book of that title. Hastie wrote much of the statistical modeling software in S-PLUS and invented principal curves and surfaces. Tibshirani proposed the Lasso and is co-author of the very successful An Introduction to the Bootstrap. Friedman is the co-inventor of many data-mining tools including CART, MARS, and projection pursuit.

FROM THE REVIEWS:

TECHNOMETRICS "[This] is a vast and complex book. Generally, it concentrates on explaining why and how the methods work, rather than how to use them. Examples and especially the visualizations are principle features...As a source for the methods of statistical learning...it will probably be a long time before there is a competitor to this book."},
  timestamp = {2016-05-17T05:02:03Z},
  urldate = {2014-12-11},
  publisher = {{Springer}},
  author = {Hastie, T and Tibshirani, R and Friedman, JH},
  month = jul,
  year = {2003},
  keywords = {machine-learning,machine-learning,statistic,statistic}
}

@article{stelzer_statistical_2013,
  title = {Statistical inference and multiple testing correction in classification-based multi-voxel pattern analysis ({{MVPA}}): {{Random}} permutations and cluster size control},
  volume = {65},
  issn = {1053-8119},
  shorttitle = {Statistical inference and multiple testing correction in classification-based multi-voxel pattern analysis ({{MVPA}})},
  doi = {10.1016/j.neuroimage.2012.09.063},
  abstract = {An ever-increasing number of functional magnetic resonance imaging (fMRI) studies are now using information-based multi-voxel pattern analysis (MVPA) techniques to decode mental states. In doing so, they achieve a significantly greater sensitivity compared to when they use univariate frameworks. However, the new brain-decoding methods have also posed new challenges for analysis and statistical inference on the group level. We discuss why the usual procedure of performing t-tests on accuracy maps across subjects in order to produce a group statistic is inappropriate. We propose a solution to this problem for local MVPA approaches, which achieves higher sensitivity than other procedures. Our method uses random permutation tests on the single-subject level, and then combines the results on the group level with a bootstrap method. To preserve the spatial dependency induced by local MVPA methods, we generate a random permutation set and keep it fixed across all locations. This enables us to later apply a cluster size control for the multiple testing problem. More specifically, we explicitly compute the distribution of cluster sizes and use this to determine the p-values for each cluster. Using a volumetric searchlight decoding procedure, we demonstrate the validity and sensitivity of our approach using both simulated and real fMRI data sets. In comparison to the standard t-test procedure implemented in SPM8, our results showed a higher sensitivity. We discuss the theoretical applicability and the practical advantages of our approach, and outline its generalization to other local MVPA methods, such as surface decoding techniques.},
  timestamp = {2015-08-26T20:55:19Z},
  urldate = {2013-08-30},
  journal = {NeuroImage},
  author = {Stelzer, Johannes and Chen, Yi and Turner, Robert},
  month = jan,
  year = {2013},
  keywords = {Cluster size control,fMRI,Multiple testing,MVPA,Second level analysis,Statistics},
  pages = {69--82},
  file = {Stelzer et al_2013_Statistical inference and multiple testing correction in classification-based.pdf:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/C9BKWQSA/Stelzer et al_2013_Statistical inference and multiple testing correction in classification-based.pdf:application/pdf;ScienceDirect Snapshot:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/2NGS4Q2G/S1053811912009810.html:text/html;ScienceDirect Snapshot:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/BX4T8DK8/S1053811912009810.html:text/html}
}

@article{jimura_analyses_2012,
  series = {Multivoxel pattern analysis and cognitive theories},
  title = {Analyses of regional-average activation and multivoxel pattern information tell complementary stories},
  volume = {50},
  issn = {0028-3932},
  doi = {10.1016/j.neuropsychologia.2011.11.007},
  abstract = {Multivariate pattern analysis (MVPA) has recently received increasing attention in functional neuroimaging due to its ability to decode mental states from fMRI signals. However, questions remain regarding both the empirical and conceptual relationships between results from MVPA and standard univariate analyses. In the current study, whole-brain univariate and searchlight MVPAs of parametric manipulations of monetary gain and loss in a decision making task (Tom et al., 2007) were compared to identify the differences in the results across these methods and the implications for understanding the underlying mental processes. The MVPA and univariate results did identify some overlapping regions in whole brain analyses. However, an analysis of consistency revealed that in many regions the effect size estimates obtained from MVPA and univariate analysis were uncorrelated. Moreover, comparison of sensitivity showed a general trend towards greater sensitivity to task manipulations by MVPA compared to univariate analysis. These results demonstrate that MVPA methods may provide a different view of the functional organization of mental processing compared to univariate analysis, wherein MVPA is more sensitive to distributed coding of information whereas univariate analysis is more sensitive to global engagement in ongoing tasks. The results also highlight the need for better ways to integrate these methods.},
  timestamp = {2015-03-19T08:14:51Z},
  number = {4},
  urldate = {2015-03-19},
  journal = {Neuropsychologia},
  author = {Jimura, Koji and Poldrack, Russell A.},
  month = mar,
  year = {2012},
  keywords = {decision-making,fMRI,MVPA,Support vector regression,Univariate analysis},
  pages = {544--552},
  file = {Jimura_Poldrack_2012_Analyses of regional-average activation and multivoxel pattern information tell.pdf:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/XHK76TX4/Jimura_Poldrack_2012_Analyses of regional-average activation and multivoxel pattern information tell.pdf:application/pdf;ScienceDirect Snapshot:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/TUQNCDIP/S0028393211005070.html:text/html}
}

@article{kriegeskorte_information-based_2006,
  title = {Information-based functional brain mapping},
  volume = {103},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.0600244103},
  abstract = {The development of high-resolution neuroimaging and multielectrode electrophysiological recording provides neuroscientists with huge amounts of multivariate data. The complexity of the data creates a need for statistical summary, but the local averaging standardly applied to this end may obscure the effects of greatest neuroscientific interest. In neuroimaging, for example, brain mapping analysis has focused on the discovery of activation, i.e., of extended brain regions whose average activity changes across experimental conditions. Here we propose to ask a more general question of the data: Where in the brain does the activity pattern contain information about the experimental condition? To address this question, we propose scanning the imaged volume with a ``searchlight,'' whose contents are analyzed multivariately at each location in the brain.},
  language = {en},
  timestamp = {2015-03-31T16:52:56Z},
  number = {10},
  urldate = {2015-03-31},
  journal = {Proceedings of the National Academy of Sciences of the United States of America},
  author = {Kriegeskorte, Nikolaus and Goebel, Rainer and Bandettini, Peter},
  month = jul,
  year = {2006},
  keywords = {Functional Magnetic Resonance Imaging,Neuroimaging,Statistical analysis},
  pages = {3863--3868},
  file = {Kriegeskorte et al_2006_Information-based functional brain mapping.pdf:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/SGBTJT8B/Kriegeskorte et al_2006_Information-based functional brain mapping.pdf:application/pdf;Snapshot:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/P9ADDW3Q/3863.html:text/html},
  pmid = {16537458}
}

@book{anderson_introduction_2003,
  address = {Hoboken, NJ},
  edition = {3 edition},
  title = {An {{Introduction}} to {{Multivariate Statistical Analysis}}},
  isbn = {978-0-471-36091-9},
  abstract = {Perfected over three editions and more than forty years, this field- and classroom-tested reference: * Uses the method of maximum likelihood to a large extent to ensure reasonable, and in some cases optimal procedures. * Treats all the basic and important topics in multivariate statistics. * Adds two new chapters, along with a number of new sections. * Provides the most methodical, up-to-date information on MV statistics available.},
  language = {English},
  timestamp = {2015-05-04T06:37:32Z},
  publisher = {{Wiley-Interscience}},
  author = {Anderson, T. W.},
  month = jul,
  year = {2003}
}

@article{srivastava_two_2013,
  title = {A two sample test in high dimensional data},
  volume = {114},
  issn = {0047-259X},
  doi = {10.1016/j.jmva.2012.08.014},
  abstract = {In this paper we propose a test for testing the equality of the mean vectors of two groups with unequal covariance matrices based on N 1 and N 2 independently distributed p -dimensional observation vectors. It will be assumed that N 1 observation vectors from the first group are normally distributed with mean vector \ensuremath{\mu} 1 and covariance matrix \ensuremath{\Sigma} 1 . Similarly, the N 2 observation vectors from the second group are normally distributed with mean vector \ensuremath{\mu} 2 and covariance matrix \ensuremath{\Sigma} 2 . We propose a test for testing the hypothesis that \ensuremath{\mu} 1 = \ensuremath{\mu} 2 . This test is invariant under the group of p \texttimes{} p nonsingular diagonal matrices. The asymptotic distribution is obtained as ( N 1 , N 2 , p ) \ensuremath{\rightarrow} \ensuremath{\infty} and N 1 / ( N 1 + N 2 ) \ensuremath{\rightarrow} k \ensuremath{\in} ( 0 , 1 ) but N 1 / p and N 2 / p may go to zero or infinity. It is compared with a recently proposed non-invariant test. It is shown that the proposed test performs the best.},
  timestamp = {2015-05-31T14:04:32Z},
  urldate = {2015-05-31},
  journal = {Journal of Multivariate Analysis},
  author = {Srivastava, Muni S. and Katayama, Shota and Kano, Yutaka},
  month = feb,
  year = {2013},
  keywords = {Asymptotic theory,Behrens–Fisher problem,High-dimensional data,Hypothesis testing},
  pages = {349--358},
  file = {Srivastava et al_2013_A two sample test in high dimensional data.pdf:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/HITJM4F3/Srivastava et al_2013_A two sample test in high dimensional data.pdf:application/pdf;ScienceDirect Snapshot:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/T8KIS5U9/S0047259X12002126.html:text/html}
}

@article{srivastava_testing_2013,
  title = {On testing the equality of mean vectors in high dimension},
  volume = {17},
  issn = {2228-4699},
  doi = {10.12697/ACUTM.2013.17.03},
  abstract = {In this article, we review various tests that have been proposed in the literature for testing the equality of several mean vectors. In particular, it includes testing the equality of two mean vectors, the so-called two-sample problem as well as that of testing the equality of several mean vectors, the so-called multivariate analysis of variance or MANOVA problem. The total sample size, however, may be less than the dimension of the mean vectors, and so usual tests cannot be used. Powers of these tests are compared using simulation.},
  language = {en},
  timestamp = {2016-02-01T12:13:48Z},
  number = {1},
  urldate = {2015-06-01},
  journal = {Acta et Commentationes Universitatis Tartuensis de Mathematica},
  author = {Srivastava, Muni S.},
  month = jun,
  year = {2013},
  keywords = {Equality of two mean vectors,high dimensional,inequality of two covariance matrices,Multivariate analysis of variance,sample smaller than dimension},
  pages = {31--56},
  file = {Srivastava_2013_On testing the equality of mean vectors in high dimension.pdf:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/CES3WQ63/Srivastava_2013_On testing the equality of mean vectors in high dimension.pdf:application/pdf;Snapshot:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/52BRBUCE/ACUTM.2013.17.html:text/html}
}

@article{srivastava_test_2008,
  title = {A test for the mean vector with fewer observations than the dimension},
  volume = {99},
  issn = {0047-259X},
  doi = {10.1016/j.jmva.2006.11.002},
  abstract = {In this paper, we consider a test for the mean vector of independent and identically distributed multivariate normal random vectors where the dimension p is larger than or equal to the number of observations N. This test is invariant under scalar transformations of each component of the random vector. Theories and simulation results show that the proposed test is superior to other two tests available in the literature. Interest in such significance test for high-dimensional data is motivated by DNA microarrays. However, the methodology is valid for any application which involves high-dimensional data.},
  timestamp = {2015-06-01T11:56:51Z},
  number = {3},
  urldate = {2015-06-01},
  journal = {Journal of Multivariate Analysis},
  author = {Srivastava, Muni S. and Du, Meng},
  month = mar,
  year = {2008},
  keywords = {Asymptotic distribution,DNA microarray,Multivariate normal,Power comparison,Significance test},
  pages = {386--402},
  file = {Srivastava_Du_2008_A test for the mean vector with fewer observations than the dimension.pdf:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/7GXHRAJV/Srivastava_Du_2008_A test for the mean vector with fewer observations than the dimension.pdf:application/pdf;ScienceDirect Snapshot:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/ZM7JH2QS/S0047259X06001990.html:text/html}
}

@article{pernet_human_2015,
  title = {The human voice areas: {{Spatial}} organization and inter-individual variability in temporal and extra-temporal cortices},
  volume = {119},
  issn = {1053-8119},
  shorttitle = {The human voice areas},
  doi = {10.1016/j.neuroimage.2015.06.050},
  abstract = {fMRI studies increasingly examine functions and properties of non-primary areas of human auditory cortex. However there is currently no standardized localization procedure to reliably identify specific areas across individuals such as the standard `localizers' available in the visual domain. Here we present an fMRI `voice localizer' scan allowing rapid and reliable localization of the voice-sensitive `temporal voice areas' (TVA) of human auditory cortex. We describe results obtained using this standardized localizer scan in a large cohort of normal adult subjects. Most participants (94\%) showed bilateral patches of significantly greater response to vocal than non-vocal sounds along the superior temporal sulcus/gyrus (STS/STG). Individual activation patterns, although reproducible, showed high inter-individual variability in precise anatomical location. Cluster analysis of individual peaks from the large cohort highlighted three bilateral clusters of voice-sensitivity, or ``voice patches'' along posterior (TVAp), mid (TVAm) and anterior (TVAa) STS/STG, respectively. A series of extra-temporal areas including bilateral inferior prefrontal cortex and amygdalae showed small, but reliable voice-sensitivity as part of a large-scale cerebral voice network. Stimuli for the voice localizer scan and probabilistic maps in MNI space are available for download.},
  timestamp = {2016-05-03T07:43:38Z},
  urldate = {2015-08-13},
  journal = {NeuroImage},
  author = {Pernet, Cyril R. and McAleer, Phil and Latinus, Marianne and Gorgolewski, Krzysztof J. and Charest, Ian and Bestelmeyer, Patricia E. G. and Watson, Rebecca H. and Fleming, David and Crabbe, Frances and Valdes-Sosa, Mitchell and Belin, Pascal},
  month = oct,
  year = {2015},
  keywords = {Amygdala,Auditory Cortex,Functional Magnetic Resonance Imaging,Inferior prefrontal cortex,Superior temporal gyrus,Superior temporal sulcus,Voice},
  pages = {164--174},
  file = {Pernet et al_2015_The human voice areas.pdf:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/K5P9IBIC/Pernet et al_2015_The human voice areas.pdf:application/pdf;Pernet et al_2015_The human voice areas.pdf:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/TMDRCDKR/Pernet et al_2015_The human voice areas.pdf:application/pdf;ScienceDirect Snapshot:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/CPWNAN2U/S1053811915005558.html:text/html;ScienceDirect Snapshot:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/DUHB2G28/S1053811915005558.html:text/html}
}

@article{mumford_impact_2014,
  title = {The impact of study design on pattern estimation for single-trial multivariate pattern analysis},
  volume = {103},
  issn = {1053-8119},
  doi = {10.1016/j.neuroimage.2014.09.026},
  abstract = {A prerequisite for a pattern analysis using functional magnetic resonance imaging (fMRI) data is estimating the patterns from time series data, which then are input into the pattern analysis. Here we focus on how the combination of study design (order and spacing of trials) with pattern estimator impacts the Type I error rate of the subsequent pattern analysis. When Type I errors are inflated, the results are no longer valid, so this work serves as a guide for designing and analyzing MVPA studies with controlled false positive rates. The MVPA strategies examined are pattern classification and similarity, utilizing single trial activation patterns from the same functional run. Primarily focusing on the Least Squares Single and Least Square All pattern estimators, we show that collinearities in the models, along with temporal autocorrelation, can cause false positive correlations between activation pattern estimates that adversely impact the false positive rates of pattern similarity and classification analyses. It may seem intuitive that increasing the interstimulus interval (ISI) would alleviate this issue, but remaining weak correlations between activation patterns persist and have a strong influence in pattern similarity analyses. Pattern similarity analyses using only activation patterns estimated from the same functional run of data are susceptible to inflated false positives unless trials are randomly ordered, with a different randomization for each subject. In other cases, where there is any structure to trial order, valid pattern similarity analysis results can only be obtained if similarity computations are restricted to pairs of activation patterns from independent runs. Likewise, for pattern classification, false positives are minimized when the testing and training sets in cross validation do not contain patterns estimated from the same run.},
  timestamp = {2016-03-20T21:16:42Z},
  urldate = {2016-03-20},
  journal = {NeuroImage},
  author = {Mumford, Jeanette A. and Davis, Tyler and Poldrack, Russell A.},
  month = dec,
  year = {2014},
  keywords = {False positive rate,fMRI,MVPA,pattern classification,Pattern similarity},
  pages = {130--138},
  file = {Mumford et al_2014_The impact of study design on pattern estimation for single-trial multivariate.pdf:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/ZXGTRKTZ/Mumford et al_2014_The impact of study design on pattern estimation for single-trial multivariate.pdf:application/pdf;ScienceDirect Snapshot:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/IXZRT8C4/S105381191400768X.html:text/html}
}

@article{ramdas_classification_2016,
  title = {Classification {{Accuracy}} as a {{Proxy}} for {{Two Sample Testing}}},
  abstract = {When data analysts train a classifier and check if its accuracy is significantly different from random guessing, they are implicitly and indirectly performing a hypothesis test (two sample testing) and it is of importance to ask whether this indirect method for testing is statistically optimal or not. Given that hypothesis tests attempt to maximize statistical power subject to a bound on the allowable false positive rate, while prediction attempts to minimize statistical risk on future predictions on unseen data, we wish to study whether a predictive approach for an ultimate aim of testing is prudent. We formalize this problem by considering the two-sample mean-testing setting where one must determine if the means of two Gaussians (with known and equal covariance) are the same or not, but the analyst indirectly does so by checking whether the accuracy achieved by Fisher's LDA classifier is significantly different from chance or not. Unexpectedly, we find that the asymptotic power of LDA's sample-splitting classification accuracy is actually minimax rate-optimal in terms of problem-dependent parameters. Since prediction is commonly thought to be harder than testing, it might come as a surprise to some that solving a harder problem does not create a information-theoretic bottleneck for the easier one. On the flip side, even though the power is rate-optimal, our derivation suggests that it may be worse by a small constant factor; hence practitioners must be wary of using (admittedly flexible) prediction methods on disguised testing problems.},
  timestamp = {2016-02-15T08:29:52Z},
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1602.02210},
  primaryClass = {cs, math, stat},
  urldate = {2016-02-09},
  journal = {arXiv:1602.02210 [cs, math, stat]},
  author = {Ramdas, Aaditya and Singh, Aarti and Wasserman, Larry},
  month = feb,
  year = {2016},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Learning,Mathematics - Statistics Theory,Statistics - Machine Learning},
  file = {Ramdas et al_2016_Classification Accuracy as a Proxy for Two Sample Testing.pdf:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/MD57BQS4/Ramdas et al_2016_Classification Accuracy as a Proxy for Two Sample Testing.pdf:application/pdf;arXiv.org Snapshot:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/ANXGBH2J/1602.html:text/html}
}

@article{srivastava_multivariate_2007,
  title = {Multivariate {{Theory}} for {{Analyzing High Dimensional Data}}},
  volume = {37},
  doi = {10.14490/jjss.37.53},
  abstract = {In this article, we develop a multivariate theory for analyzing multivariate datasets that have fewer observations than dimensions. More specifically, we consider the problem of testing the hypothesis that the mean vector \ensuremath{\mu} of a p-dimensional random vector x is a zero vector where N, the number of independent observations on x, is less than the dimension p. It is assumed that x is normally distributed with mean vector \ensuremath{\mu} and unknown nonsingular covariance matrix \ensuremath{\sum}. We propose the test statistic F+ = n-2 (p - n + 1) N \textasciimacron{}x\ensuremath{'}S+\textasciimacron{}x, where n = N - 1 \ensuremath{<} p, \textasciimacron{}x and S are the sample mean vector and the sample covariance matrix respectively, and S+ is the Moore-Penrose inverse of S. It is shown that a suitably normalized version of the F+ statistic is asymptotically normally distributed under the hypothesis. The asymptotic non-null distribution in one sample case is given. The case when the covariance matrix \ensuremath{\sum} is singular of rank r but the sample size N is larger than r is also considered. The corresponding results for the case of two-samples and k samples, known as MANOVA, are given.},
  timestamp = {2016-02-17T04:59:33Z},
  number = {1},
  journal = {Journal of the Japan Statistical Society},
  author = {Srivastava, M. S.},
  year = {2007},
  keywords = {Distribution of test statistics,DNA microarray data,Fewer observations than dimension,Multivariate analysis of variance,Singular Wishart},
  pages = {53--86},
  file = {Srivastava_2007_Multivariate Theory for Analyzing High Dimensional Data.pdf:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/RN68APQJ/Srivastava_2007_Multivariate Theory for Analyzing High Dimensional Data.pdf:application/pdf}
}

@article{solari_rotation-based_2014,
  title = {Rotation-based multiple testing in the multivariate linear model},
  volume = {70},
  issn = {1541-0420},
  doi = {10.1111/biom.12238},
  abstract = {In observational microarray studies, issues of confounding invariably arise. One approach to account for measured confounders is to include them as covariates in a multivariate linear model. For this model, however, the application of permutation-based multiple testing procedures is problematic because exchangeability of responses, in general, does not hold. Nevertheless, it is possible to achieve rotatability of transformed responses at the cost of a distributional assumption. We argue that rotation-based multiple testing, by allowing for adjustments for confounding, represents an important extension of permutation-based multiple testing procedures. The proposed methodology is illustrated with a microarray observational study on breast cancer tumors. Software to perform the procedure described in this article is available in the flip R package.},
  language = {eng},
  timestamp = {2016-05-03T07:43:49Z},
  number = {4},
  journal = {Biometrics},
  author = {Solari, Aldo and Finos, Livio and Goeman, Jelle J.},
  month = dec,
  year = {2014},
  keywords = {Algorithms,Computer Simulation,Data Interpretation; Statistical,Exchangeability,Familywise error rate,Gene Expression Profiling,Linear Models,Microarray,Multiple testing,MULTIVARIATE ANALYSIS,Oligonucleotide Array Sequence Analysis,permutation test,Reproducibility of Results,Rotation,Rotation test,Sensitivity and Specificity},
  pages = {954--961},
  file = {Solari et al_2014_Rotation-based multiple testing in the multivariate linear model.pdf:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/K58SI7DW/Solari et al_2014_Rotation-based multiple testing in the multivariate linear model.pdf:application/pdf;Snapshot:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/JCQP4FCG/abstract.html:text/html},
  pmid = {25269416}
}

@article{langsrud_rotation_2005,
  title = {Rotation tests},
  volume = {15},
  issn = {0960-3174, 1573-1375},
  doi = {10.1007/s11222-005-4789-5},
  abstract = {This paper describes a generalised framework for doing Monte Carlo tests in multivariate linear regression. The rotation methodology assumes multivariate normality and is a true generalisation of the classical multivariate tests\textemdash{}any imaginable test statistic is allowed. The generalised test statistics are dependent on the unknown covariance matrix. Rotation testing handles this problem by conditioning on sufficient statistics. Compared to permutation tests, we replace permutations by proper random rotations. Permutation tests avoid the multinormal assumption, but they are limited to relatively simple models. On the other hand, a rotation test can, in particular, be applied to any multivariate generalisation of the univariate F-test. As an important application, a detailed description of how each single response p-value can be non-conservatively adjusted for multiplicity is given. This method is exact and non-conservative (unlike Bonferroni), and it is a generalisation of the ordinary F-test (except for the computation by simulations). Hence, this paper offers an exact Monte Carlo solution to a classical problem of multiple testing.},
  language = {en},
  timestamp = {2016-07-17T14:40:19Z},
  number = {1},
  urldate = {2016-04-29},
  journal = {Statistics and Computing},
  author = {Langsrud, \O{}yvind},
  month = jan,
  year = {2005},
  keywords = {Adjusted p-value,Artificial Intelligence (incl. Robotics),Conditional inference,Data Structures; Cryptology and Information Theory,microarray data analysis,multiple endpoints,Multiple testing,Numeric Computing,random orthogonal matrix,spherical distribution,Statistics; general},
  pages = {53--60},
  file = {Langsrud_2005_Rotation tests.pdf:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/PA3CDIHR/Langsrud_2005_Rotation tests.pdf:application/pdf;Snapshot:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/2ZPXS5EP/10.html:text/html}
}

@book{fujikoshi_multivariate_2011,
  title = {Multivariate {{Statistics}}: {{High-Dimensional}} and {{Large-Sample Approximations}}},
  isbn = {978-0-470-53986-6},
  shorttitle = {Multivariate {{Statistics}}},
  abstract = {A comprehensive examination of high-dimensional analysis of multivariate methods and their real-world applications Multivariate Statistics: High-Dimensional and Large-Sample Approximations is the first book of its kind to explore how classical multivariate methods can be revised and used in place of conventional statistical tools. Written by prominent researchers in the field, the book focuses on high-dimensional and large-scale approximations and details the many basic multivariate methods used to achieve high levels of accuracy. The authors begin with a fundamental presentation of the basic tools and exact distributional results of multivariate statistics, and, in addition, the derivations of most distributional results are provided. Statistical methods for high-dimensional data, such as curve data, spectra, images, and DNA microarrays, are discussed. Bootstrap approximations from a methodological point of view, theoretical accuracies in MANOVA tests, and model selection criteria are also presented. Subsequent chapters feature additional topical coverage including:  High-dimensional approximations of various statistics High-dimensional statistical methods Approximations with computable error bound Selection of variables based on model selection approach Statistics with error bounds and their appearance in discriminant analysis, growth curve models, generalized linear models, profile analysis, and multiple comparison  Each chapter provides real-world applications and thorough analyses of the real data. In addition, approximation formulas found throughout the book are a useful tool for both practical and theoretical statisticians, and basic results on exact distributions in multivariate analysis are included in a comprehensive, yet accessible, format. Multivariate Statistics is an excellent book for courses on probability theory in statistics at the graduate level. It is also an essential reference for both practical and theoretical statisticians who are interested in multivariate analysis and who would benefit from learning the applications of analytical probabilistic methods in statistics.},
  language = {en},
  timestamp = {2016-05-01T07:19:13Z},
  publisher = {{John Wiley \& Sons}},
  author = {Fujikoshi, Yasunori and Ulyanov, Vladimir V. and Shimizu, Ryoichi},
  month = aug,
  year = {2011},
  keywords = {Mathematics / Probability \& Statistics / General,Mathematics / Probability \& Statistics / Stochastic Processes}
}

@article{langsrud_geometrical_2004,
  title = {The geometrical interpretation of statistical tests in multivariate linear regression},
  volume = {45},
  issn = {0932-5026, 1613-9798},
  doi = {10.1007/BF02778273},
  abstract = {A geometrical interpretation of the classical tests of the relation between two sets of variables is presented. One of the variable sets may be considered as fixed and then we have a multivariate regression model. When the Wilks' lambda distribution is viewed geometrically it is obvious that the two special cases, theF distribution and the HotellingT 2 distribution are equivalent. From the geometrical perspective it is also obvious that the test statistic and thep-value are unchanged if the responses and the predictors are interchanged.},
  language = {en},
  timestamp = {2016-04-29T11:51:10Z},
  number = {1},
  urldate = {2016-04-29},
  journal = {Statistical Papers},
  author = {Langsrud, \O{}yvind},
  month = jan,
  year = {2004},
  keywords = {Canonical correlation,Economic Theory,Invariance,MANOVA,MULTIVARIATE ANALYSIS,Operations Research/Decision Theory,Probability Theory and Stochastic Processes,Random rotation,Statistics for Business/Economics/Mathematical Finance/Insurance,Wilks’ lambda distribution},
  pages = {111--122},
  file = {Langsrud_2004_The geometrical interpretation of statistical tests in multivariate linear.pdf:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/JCTHC533/Langsrud_2004_The geometrical interpretation of statistical tests in multivariate linear.pdf:application/pdf;Snapshot:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/F2IP6AWU/10.html:text/html}
}

@article{ojala_permutation_2010,
  title = {Permutation {{Tests}} for {{Studying Classifier Performance}}},
  volume = {11},
  issn = {ISSN 1533-7928},
  timestamp = {2016-07-04T17:58:55Z},
  number = {Jun},
  urldate = {2016-07-04},
  journal = {Journal of Machine Learning Research},
  author = {Ojala, Markus and Garriga, Gemma C.},
  year = {2010},
  pages = {1833--1863},
  file = {Ojala_Garriga_2010_Permutation Tests for Studying Classifier Performance.pdf:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/3JAFGW2X/Ojala_Garriga_2010_Permutation Tests for Studying Classifier Performance.pdf:application/pdf;Snapshot:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/Z5T8DEE6/ojala10a.html:text/html}
}

@article{schafer_shrinkage_2005,
  title = {A shrinkage approach to large-scale covariance matrix estimation and implications for functional genomics},
  volume = {4},
  timestamp = {2016-07-04T21:03:44Z},
  number = {1},
  urldate = {2016-07-04},
  journal = {Statistical applications in genetics and molecular biology},
  author = {Sch{\"a}fer, Juliane and Strimmer, Korbinian and {others}},
  year = {2005},
  pages = {32},
  file = {Schäfer et al_2005_A shrinkage approach to large-scale covariance matrix estimation and.pdf:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/AXE5W4FW/Schäfer et al_2005_A shrinkage approach to large-scale covariance matrix estimation and.pdf:application/pdf}
}

@unpublished{varoquaux_assessing_2016,
  title = {Assessing and tuning brain decoders: cross-validation, caveats, and guidelines},
  shorttitle = {Assessing and tuning brain decoders},
  abstract = {Decoding, ie prediction from brain images or signals, calls for empirical evaluation of its predictive power. Such evaluation is achieved via cross-validation, a method also used to tune decoders' hyper-parameters. This paper is a review on cross-validation procedures for decoding in neuroimaging. It includes a didactic overview of the relevant theoretical considerations. Practical aspects are highlighted with an extensive empirical study of the common decoders in within-and across-subject predictions, on multiple datasets \textendash{}anatomical and functional MRI and MEG\textendash{} and simulations. Theory and experiments outline that the popular " leave-one-out " strategy leads to unstable and biased estimates, and a repeated random splits method should be preferred. Experiments outline the large error bars of cross-validation in neuroimaging settings: typical confidence intervals of 10\%. Nested cross-validation can tune decoders' parameters while avoiding circularity bias. However we find that it can be more favorable to use sane defaults, in particular for non-sparse decoders.},
  timestamp = {2016-07-04T21:08:54Z},
  urldate = {2016-07-04},
  author = {Varoquaux, Ga{\"e}l and Raamana, Pradeep Reddy and Engemann, Denis and Hoyos-Idrobo, Andr{\'e}s and Schwartz, Yannick and Thirion, Bertrand},
  month = jun,
  year = {2016},
  note = {working paper or preprint},
  keywords = {Bagging,cross-validation,Decoding,fMRI,Model selection,MVPA,sparse},
  file = {Varoquaux et al_2016_Assessing and tuning brain decoders.pdf:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/GM2G3W2W/Varoquaux et al_2016_Assessing and tuning brain decoders.pdf:application/pdf;HAL Snapshot:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/XSPCKFJR/hal-01332785.html:text/html}
}

@inproceedings{golland_permutation_2003,
  title = {Permutation tests for classification: towards statistical significance in image-based studies},
  volume = {3},
  shorttitle = {Permutation tests for classification},
  timestamp = {2016-07-05T10:33:44Z},
  urldate = {2016-07-05},
  booktitle = {{{IPMI}}},
  publisher = {{Springer}},
  author = {Golland, Polina and Fischl, Bruce},
  year = {2003},
  pages = {330--341},
  file = {Golland_Fischl_2003_Permutation tests for classification.pdf:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/KIFCRANG/Golland_Fischl_2003_Permutation tests for classification.pdf:application/pdf;Snapshot:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/5PZMV3JR/b11820.html:text/html}
}

@inproceedings{kohavi_study_1995-1,
  title = {A study of cross-validation and bootstrap for accuracy estimation and model selection},
  volume = {14},
  timestamp = {2016-07-08T17:24:31Z},
  urldate = {2016-07-08},
  booktitle = {Ijcai},
  author = {Kohavi, Ron and {others}},
  year = {1995},
  pages = {1137--1145}
}

@article{southworth_properties_2009,
  title = {Properties of {{Balanced Permutations}}},
  volume = {16},
  issn = {1066-5277},
  doi = {10.1089/cmb.2008.0144},
  abstract = {This paper takes a close look at balanced permutations, a recently developed sample reuse method with applications in bioinformatics. It turns out that balanced permutation reference distributions do not have the correct null behavior, which can be traced to their lack of a group structure. We find that they can give p-values that are too permissive to varying degrees. In particular the observed test statistic can be larger than that of all B balanced permutations of a data set with a probability much higher than 1/(B\,+\,1), even under the null hypothesis.},
  timestamp = {2016-07-24T06:23:57Z},
  number = {4},
  urldate = {2016-07-17},
  journal = {Journal of Computational Biology},
  author = {Southworth, Lucinda K. and Kim, Stuart K. and Owen, Art B.},
  month = apr,
  year = {2009},
  keywords = {Seminal},
  pages = {625--638},
  file = {Southworth et al_2009_Properties of Balanced Permutations.pdf:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/RB2PIUV5/Southworth et al_2009_Properties of Balanced Permutations.pdf:application/pdf;Snapshot:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/FFPEPRUF/cmb.2008.html:text/html}
}

@article{radmacher_paradigm_2002,
  title = {A {{Paradigm}} for {{Class Prediction Using Gene Expression Profiles}}},
  volume = {9},
  issn = {1066-5277},
  doi = {10.1089/106652702760138592},
  abstract = {We propose a general framework for prediction of predefined tumor classes using gene expression profiles from microarray experiments. The framework consists of 1) evaluating the appropriateness of class          prediction for the given data set, 2) selecting the prediction method, 3) performing cross-validated class prediction, and 4) assessing the significance of prediction results by permutation testing. We          describe an application of the prediction paradigm to gene expression profiles from human breast cancers, with specimens classified as positive or negative for BRCA1 mutations and also for BRCA2          mutations. In both cases, the accuracy of class prediction was statistically significant when compared to the accuracy of prediction expected by chance. The framework proposed here for the application of          class prediction is designed to reduce the occurrence of spurious findings, a legitimate concern for high-dimensional microarray data. The prediction paradigm will serve as a good framework for comparing          different prediction methods and may accelerate the development of molecular classifiers that are clinically useful.},
  timestamp = {2016-07-21T08:48:15Z},
  number = {3},
  urldate = {2016-07-21},
  journal = {Journal of Computational Biology},
  author = {Radmacher, Michael D. and McShane, Lisa M. and Simon, Richard},
  month = jun,
  year = {2002},
  pages = {505--511},
  file = {Radmacher et al_2002_A Paradigm for Class Prediction Using Gene Expression Profiles.pdf:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/RE86PPTC/Radmacher et al_2002_A Paradigm for Class Prediction Using Gene Expression Profiles.pdf:application/pdf;Snapshot:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/MP5I69DB/106652702760138592.html:text/html}
}

@article{nadeau_inference_????,
  title = {Inference for the {{Generalization Error}}},
  volume = {52},
  issn = {0885-6125, 1573-0565},
  doi = {10.1023/A:1024068626366},
  abstract = {In order to compare learning algorithms, experimental results reported in the machine learning literature often use statistical tests of significance to support the claim that a new learning algorithm generalizes better. Such tests should take into account the variability due to the choice of training set and not only that due to the test examples, as is often the case. This could lead to gross underestimation of the variance of the cross-validation estimator, and to the wrong conclusion that the new algorithm is significantly better when it is not. We perform a theoretical investigation of the variance of a variant of the cross-validation estimator of the generalization error that takes into account the variability due to the randomness of the training set as well as test examples. Our analysis shows that all the variance estimators that are based only on the results of the cross-validation experiment must be biased. This analysis allows us to propose new estimators of this variance. We show, via simulations, that tests of hypothesis about the generalization error using those new variance estimators have better properties than tests involving variance estimators currently in use and listed in Dietterich (1998). In particular, the new tests have correct size and good power. That is, the new tests do not reject the null hypothesis too often when the hypothesis is true, but they tend to frequently reject the null hypothesis when the latter is false.},
  language = {en},
  timestamp = {2016-07-21T08:56:33Z},
  number = {3},
  urldate = {2016-07-21},
  journal = {Machine Learning},
  author = {Nadeau, Claude and Bengio, Yoshua},
  pages = {239--281},
  file = {Nadeau_Bengio_Inference for the Generalization Error.pdf:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/TDV3832D/Nadeau_Bengio_Inference for the Generalization Error.pdf:application/pdf;Snapshot:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/7SKKZM3H/A1024068626366.html:text/html}
}

@article{jiang_calculating_2008,
  title = {Calculating confidence intervals for prediction error in microarray classification using resampling},
  volume = {7},
  timestamp = {2016-07-21T09:02:59Z},
  number = {1},
  urldate = {2016-07-21},
  journal = {Statistical Applications in Genetics and Molecular Biology},
  author = {Jiang, Wenyu and Varma, Sudhir and Simon, Richard},
  year = {2008},
  file = {Jiang et al_2008_Calculating confidence intervals for prediction error in microarray.pdf:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/XSSU5F5W/Jiang et al_2008_Calculating confidence intervals for prediction error in microarray.pdf:application/pdf;Snapshot:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/4H86NDA9/sagmb.2008.7.1.1322.html:text/html}
}

@article{gilron_quantifying_2016,
  title = {Quantifying spatial pattern similarity in multivariate analysis using functional anisotropy},
  abstract = {Multivoxel pattern analysis (MVPA) has gained enormous popularity in the neuroimaging community over the past few years. At the group level, most MVPA studies adopt an "information based" approach in which the sign of the effect of individual subjects is discarded and a non-directional summary statistic is carried over to the second level. This is in contrast to a directional "activation based" approach which is typical in univariate group level analysis, in which both signal magnitude and sign are taken into account. The transition from examining effects in one voxel at a time vs. several voxels (univariate vs. multivariate) has thus tacitly entailed a transition from directional to non-directional signal definition at the group level. While a directional MVPA approach implies that individuals share multivariate spatial patterns of activity, in a non-directional approach each individual may have a distinct spatial pattern of activity. Here we show using an experimental dataset that indeed directional and non-directional MVPA approaches uncover distinct brain regions with some overlap. Moreover, we developed a descriptive measure to quantify the degree to which subjects share spatial patterns of activity. Our approach is based on adapting the Fractional Anisotropy (FA) measure, originally developed for examining diffusion MRI signals, in a novel way to quantify the degree to which subjects share a spatial pattern of activity. We term this measure "Functional Anisotropy" (FuA). Applying FuA to an auditory task, we found higher values in primary auditory regions compared to secondary and control regions. This highlights the potential of the FuA measure in second-level MVPA analysis to detect differences in the consistency of spatial patterns across subjects and their relationship to functional domains in the brain.},
  timestamp = {2016-07-26T04:06:39Z},
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1605.03482},
  primaryClass = {q-bio},
  urldate = {2016-07-26},
  journal = {arXiv:1605.03482 [q-bio]},
  author = {Gilron, Roee and Rosenblatt, Jonathan and Koyejo, Oluwasanmi and Poldrack, Russell A. and Mukamel, Roy},
  month = may,
  year = {2016},
  keywords = {Quantitative Biology - Neurons and Cognition,Quantitative Biology - Quantitative Methods},
  file = {Gilron et al_2016_Quantifying spatial pattern similarity in multivariate analysis using.pdf:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/3AE7RZEB/Gilron et al_2016_Quantifying spatial pattern similarity in multivariate analysis using.pdf:application/pdf;arXiv.org Snapshot:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/F5VJ3TWX/1605.html:text/html}
}

@article{hemerik_exact_2014-1,
  title = {Exact testing with random permutations},
  abstract = {Permutation tests and other methods based on the permutation principle are highly popular, for instance in omics data analysis. Often random permutations are used, to limit the computation time. However, the existing theory on permutation tests usually assumes that all permutations are enumerated; little theory exists on testing with random permutations. It is known that naively using random permutations instead of the full permutation group, leads to anti-conservativeness. Also it has been claimed that adding the original observation to the random permutations solves this problem. A proof however is lacking. In this paper existing claims on validity of tests with random permutations are proven. Further, novel exact tests are presented.},
  timestamp = {2016-07-27T08:31:25Z},
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1411.7565},
  primaryClass = {math, stat},
  urldate = {2016-07-27},
  journal = {arXiv:1411.7565 [math, stat]},
  author = {Hemerik, Jesse and Goeman, Jelle},
  month = nov,
  year = {2014},
  keywords = {62G09,Mathematics - Statistics Theory},
  file = {Hemerik_Goeman_2014_Exact testing with random permutations.pdf:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/DK287DKI/Hemerik_Goeman_2014_Exact testing with random permutations.pdf:application/pdf;arXiv.org Snapshot:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/GKQ23FZS/1411.html:text/html}
}

@article{pereira_machine_2009,
  series = {Mathematics in Brain Imaging},
  title = {Machine learning classifiers and {{fMRI}}: {{A}} tutorial overview},
  volume = {45},
  issn = {1053-8119},
  shorttitle = {Machine learning classifiers and {{fMRI}}},
  doi = {10.1016/j.neuroimage.2008.11.007},
  abstract = {Interpreting brain image experiments requires analysis of complex, multivariate data. In recent years, one analysis approach that has grown in popularity is the use of machine learning algorithms to train classifiers to decode stimuli, mental states, behaviours and other variables of interest from fMRI data and thereby show the data contain information about them. In this tutorial overview we review some of the key choices faced in using this approach as well as how to derive statistically significant results, illustrating each point from a case study. Furthermore, we show how, in addition to answering the question of `is there information about a variable of interest' (pattern discrimination), classifiers can be used to tackle other classes of question, namely `where is the information' (pattern localization) and `how is that information encoded' (pattern characterization).},
  timestamp = {2016-07-28T05:45:34Z},
  number = {1, Supplement 1},
  urldate = {2016-07-28},
  journal = {NeuroImage},
  author = {Pereira, Francisco and Mitchell, Tom and Botvinick, Matthew},
  month = mar,
  year = {2009},
  pages = {S199--S209},
  file = {Pereira et al_2009_Machine learning classifiers and fMRI.pdf:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/BNQ4Z2SM/Pereira et al_2009_Machine learning classifiers and fMRI.pdf:application/pdf;ScienceDirect Snapshot:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/SIQXCRCC/S1053811908012263.html:text/html}
}

@incollection{olivetti_induction_2012,
  series = {Lecture Notes in Computer Science},
  title = {Induction in {{Neuroscience}} with {{Classification}}: {{Issues}} and {{Solutions}}},
  copyright = {\textcopyright{}2012 Springer-Verlag Berlin Heidelberg},
  isbn = {978-3-642-34712-2 978-3-642-34713-9},
  shorttitle = {Induction in {{Neuroscience}} with {{Classification}}},
  abstract = {Machine learning and pattern recognition techniques are increasingly adopted in neuroimaging-based neuroscience research. In many applications a classifier is trained on brain data in order to predict a variable of interest. Two leading examples are brain decoding and clinical diagnosis. Brain decoding consists of predicting stimuli or mental states from concurrent functional brain data. In clinical diagnosis it is the presence or absence of a given medical condition that is predicted from brain data. Observing accurate classification is considered to support the hypothesis of variable-related information within brain data. In this work we briefly review the literature on statistical tests for this kind of hypothesis testing problem. We claim that the current approaches to this hypothesis testing problem are suboptimal, do not cover all useful settings, and that they could lead to wrong conclusions. We present a more accurate statistical test and provide examples of its superiority.},
  language = {en},
  timestamp = {2016-07-28T05:46:50Z},
  number = {7263},
  urldate = {2016-07-28},
  booktitle = {Machine {{Learning}} and {{Interpretation}} in {{Neuroimaging}}},
  publisher = {{Springer Berlin Heidelberg}},
  author = {Olivetti, Emanuele and Greiner, Susanne and Avesani, Paolo},
  editor = {Langs, Georg and Rish, Irina and Grosse-Wentrup, Moritz and Murphy, Brian},
  year = {2012},
  keywords = {Computer Applications,Computer Imaging; Vision; Pattern Recognition and Graphics,Data Mining and Knowledge Discovery,Image Processing and Computer Vision,pattern recognition,Probability and Statistics in Computer Science},
  pages = {42--50},
  file = {Olivetti et al_2012_Induction in Neuroscience with Classification.pdf:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/DNCZRCNJ/Olivetti et al_2012_Induction in Neuroscience with Classification.pdf:application/pdf;Snapshot:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/TF8AQ2N9/978-3-642-34713-9_6.html:text/html},
  doi = {10.1007/978-3-642-34713-9_6}
}

@article{simon_pitfalls_2003,
  title = {Pitfalls in the {{Use}} of {{DNA Microarray Data}} for {{Diagnostic}} and {{Prognostic Classification}}},
  volume = {95},
  issn = {0027-8874, 1460-2105},
  doi = {10.1093/jnci/95.1.14},
  language = {en},
  timestamp = {2016-07-28T06:02:48Z},
  number = {1},
  urldate = {2016-07-28},
  journal = {Journal of the National Cancer Institute},
  author = {Simon, Richard and Radmacher, Michael D. and Dobbin, Kevin and McShane, Lisa M.},
  month = jan,
  year = {2003},
  pages = {14--18},
  file = {Simon et al_2003_Pitfalls in the Use of DNA Microarray Data for Diagnostic and Prognostic.pdf:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/S2N3HXB2/Simon et al_2003_Pitfalls in the Use of DNA Microarray Data for Diagnostic and Prognostic.pdf:application/pdf;Snapshot:/home/johnros/.zotero/zotero/66g0wvis.default/zotero/storage/TPKZHDS4/14.html:text/html},
  pmid = {12509396}
}


